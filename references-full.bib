% This file was created with JabRef 2.10.
% Encoding: ISO8859_1


@Article{Adelson1992,
  Title                    = {{Single lens stereo with a plenoptic camera}},
  Author                   = {Adelson, E.H. and Wang, J.Y.a.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1992},
  Number                   = {2},
  Pages                    = {99--106},
  Volume                   = {14},

  Doi                      = {10.1109/34.121783},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adelson, Wang - 1992 - Single lens stereo with a plenoptic camera.pdf:pdf},
  ISSN                     = {01628828},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=121783}
}

@InProceedings{ahmad1989scaling,
  Title                    = {Scaling and generalization in neural networks: a case study},
  Author                   = {Ahmad, Subutai and Tesauro, Gerald},
  Booktitle                = {Advances in neural information processing systems},
  Year                     = {1989},
  Pages                    = {160--168},

  Owner                    = {yani},
  Timestamp                = {2017.09.13}
}

@Article{journals/neco/AmitG97,
  Title                    = {{Shape Quantization And Recognition With Randomized Trees.}},
  Author                   = {Amit, Yali and Geman, Donald},
  Journal                  = {Neural Computation},
  Year                     = {1997},
  Number                   = {7},
  Pages                    = {1545--1588},
  Volume                   = {9},

  Keywords                 = {dblp},
  Url                      = {http://dblp.uni-trier.de/db/journals/neco/neco9.html{\#}AmitG97}
}

@InCollection{NIPS2014_5484,
  Title                    = {{Do Deep Nets Really Need to be Deep?}},
  Author                   = {Ba, Jimmy and Caruana, Rich},
  Booktitle                = {{Advances in Neural Information Processing Systems 27}},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2014},
  Editor                   = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
  Pages                    = {2654--2662},

  Url                      = {http://papers.nips.cc/paper/5484-do-deep-nets-really-need-to-be-deep.pdf}
}

@InProceedings{Ba2013dothey,
  Title                    = {{Do Deep Nets Really Need to be Deep ?}},
  Author                   = {Ba, Lj and Caurana, R},
  Booktitle                = {{arXiv preprint arXiv:1312.6184}},
  Year                     = {2013},
  Pages                    = {1--6},
  Volume                   = {2014},

  Abstract                 = {Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shal- low feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We eval- uate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for train- ing shallow feed-forward nets than those currently available.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1312.6184v5},
  Doi                      = {10.1038/nature14539},
  Eprint                   = {arXiv:1312.6184v5},
  ISBN                     = {3135786504},
  ISSN                     = {0028-0836},
  Pmid                     = {26017442},
  Url                      = {http://arxiv.org/abs/1312.6184}
}

@Article{Barron2012,
  Title                    = {{Shape , Albedo , and Illumination from a Single Image of an Unknown Object}},
  Author                   = {Barron, Jonathan T and Malik, Jitendra and Berkeley, U C},
  Journal                  = {IEEE Conference on Computer Vision and Patern Recognition},
  Year                     = {2012},
  Pages                    = {334--341},

  Abstract                 = {We address the problem of recovering shape, albedo, and illumination from a single grayscale image of an object, using shading as our primary cue. Because this problem is fundamentally underconstrained, we construct statistical models of albedo and shape, and define an optimization problem that searches for the most likely explanation of a single image. We present two priors on albedo which en- courage local smoothness and global sparsity, and three priors on shape which encourage flatness, outward-facing orientation at the occluding contour, and local smoothness. We present an optimization technique for using these pri- ors to recover shape, albedo, and a spherical harmonic model of illumination. Our model, which we call SAIFS (shape, albedo, and illumination from shading) produces reasonable results on arbitrary grayscale images taken in the real world, and outperforms all previous grayscale in- trinsic image-style algorithms on the MIT Intrinsic Images dataset.},
  Doi                      = {10.1109/CVPR.2012.6247693},
  ISBN                     = {9781467312288},
  ISSN                     = {10636919},
  Publisher                = {IEEE},
  Url                      = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6247693{&}contentType=Conference+Publications}
}

@Article{bartlett1997,
  Title                    = {{For valid generalization, the size of the weights is more important than the size of the network}},
  Author                   = {Bartlett, Peter L},
  Journal                  = {Advances in neural information processing systems},
  Year                     = {1997},
  Pages                    = {134--140},

  Publisher                = {MORGAN KAUFMANN PUBLISHERS}
}

@InProceedings{Bastani2016,
  Title                    = {{Measuring Neural Net Robustness with Constraints}},
  Author                   = {Bastani, Osbert and Ioannou, Yani and Lampropoulos, Leonidas and Vytiniotis, Dimitrios and Nori, Aditya and Criminisi, Antonio},
  Booktitle                = {{Neural Information Processing Systems (NIPS), 2016}},
  Year                     = {2016},

  Address                  = {Barcelona, Spain},
  Month                    = {dec},

  Abstract                 = {Despite having high accuracy, neural nets have been shown to be susceptible to adversarial examples, where a small perturbation to an input can cause it to become mislabeled. We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program. We show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the MNIST and CIFAR-10 datasets. Our algorithm generates more informative estimates of robustness metrics compared to estimates based on existing algorithms. Furthermore, we show how existing approaches to improving robustness "overfit" to adversarial examples generated using a specific algorithm. Finally, we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose, but also according to previously proposed metrics.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1605.07262},
  Eprint                   = {1605.07262},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastani et al. - 2016 - Measuring Neural Net Robustness with Constraints.pdf:pdf},
  Keywords                 = {CNN; adversarial images; deep learning; robustness},
  Mendeley-tags            = {CNN,adversarial images,deep learning,robustness},
  Url                      = {http://arxiv.org/abs/1605.07262}
}

@InProceedings{bastani2016measuring,
  Title                    = {{Measuring Neural Net Robustness with Constraints}},
  Author                   = {Bastani, Osbert and Ioannou, Yani and Lampropoulos, Leonidas and Vytiniotis, Dimitrios and Nori, Aditya and Criminisi, Antonio},
  Booktitle                = {{Neural Information Processing Systems (NIPS), 2016}},
  Year                     = {2016}
}

@InProceedings{baum1989size,
  Title                    = {{What size net gives valid generalization?}},
  Author                   = {Baum, Eric B and Haussler, David},
  Booktitle                = {{Advances in neural information processing systems}},
  Year                     = {1989},
  Pages                    = {81--90}
}

@Misc{Beacco2003,
  Title                    = {{A system for in situ measurements of road reflection properties}},

  Author                   = {Beacco, D and Fiorentin, P and Rossi, G},
  Year                     = {2003},

  Abstract                 = {The characterization of the photometric properties of a road surface is of prime importance in the design of lighting plant and when the real vision condition should be determined by computer simulation. The measurement could be done in laboratory but the in situ measurement are very interested because it permit to test several zone on the road and there is no mechanical starch on the surface of the sample. This work describes an innovative portable system based on a CCD luminance meter able to obtain uncertainty comparable in traditional laboratory systems.},
  Booktitle                = {{Proceedings of the 20th IEEE Instrumentation Technology Conference Cat No03CH37412}},
  Doi                      = {10.1109/IMTC.2003.1208001},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beacco, Fiorentin, Rossi - 2003 - A system for in situ measurements of road reflection properties.pdf:pdf},
  ISBN                     = {0780377052},
  ISSN                     = {10915281},
  Number                   = {May},
  Pages                    = {1508--1512},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1208001},
  Volume                   = {2}
}

@Article{Bellia2002,
  Title                    = {{Setting up a CCD photometer for lighting research and design}},
  Author                   = {Bellia, L and Cesarano, A and Minichiello, F and Sibilio, S},
  Journal                  = {Building and Environment},
  Year                     = {2002},
  Number                   = {11},
  Pages                    = {1099--1106},
  Volume                   = {37},

  Abstract                 = {Recent availability of video-cameras with CCD-type sensors (charge coupled device) has proved to be particularly stimulating for all those applications requiring photometric measurements, above all for the measurement of luminance values related to the physical and technical qualities of a built environment. This method allows the instantaneous capture of an image, thus enabling collection of luminance values relating to the points of measurement; this in turn leads to the evaluation of luminance distribution and lighting levels of the surfaces that make up the environment. Setting up this system requires the following basic configuration: a photopic filter V($\lambda$), an optic interface, a computer equipped with an appropriate card for the capture and digitalisation of the acquired image (the grqqframe grabber) and, finally, suitable software for the processing of collected data. In this article a detailed description of this acquisition system is reported, and subsequently a report on the procedure adopted for its calibration so as to enable the capture of relevant photometric values. Final analysis and validation of results are carried out by means of field test. A case study of CCD photometerapplication has been then performed using a basic software tool autonomously developed to evaluate indoor lighting level; the luminance map of a diffuse light source has been used as grqqinput data for the developed software, and the grqqoutput data, i.e. illumination levels, have been then compared with measured values.},
  Doi                      = {10.1016/S0360-1323(01)00093-2},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellia et al. - 2002 - Setting up a CCD photometer for lighting research and design.pdf:pdf},
  ISSN                     = {03601323},
  Keywords                 = {calculation; luminance; photometers; software code; video camera},
  Publisher                = {CIE Poland},
  Url                      = {http://linkinghub.elsevier.com/retrieve/pii/S0360132301000932}
}

@InProceedings{Bengio2010labeltree,
  Title                    = {{Label Embedding Trees for Large Multi-Class Tasks}},
  Author                   = {Bengio, S and Weston, J and Grangier, D},
  Booktitle                = {{Conference and Workshop on Neural Information Processing Systems}},
  Year                     = {2010}
}

@Article{bengio:ieeenn94,
  Title                    = {{Learning Long-Term Dependencies With Gradient Descent Is Difficult}},
  Author                   = {Bengio, Yoshua and Simard, Patrick and Frasconi, Paolo},
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {1994},
  Number                   = {2},
  Pages                    = {157--166},
  Volume                   = {5},

  Keywords                 = {nn}
}

@Book{Bishop1995,
  Title                    = {{Neural Networks for Pattern Recognition}},
  Author                   = {Bishop, Christopher M},
  Publisher                = {Oxford University Press},
  Year                     = {1995},

  Address                  = {Oxford},

  Keywords                 = {imported}
}

@InCollection{Bottou2012sgdtricks,
  Title                    = {{Stochastic Gradient Descent Tricks.}},
  Author                   = {Bottou, L{\'e}on},
  Booktitle                = {{Neural Networks: Tricks of the Trade (2nd ed.)}},
  Publisher                = {Springer},
  Year                     = {2012},
  Editor                   = {Montavon, Gr{\'e}goire and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  Pages                    = {421--436},
  Series                   = {{Lecture Notes in Computer Science}},
  Volume                   = {7700},

  ISBN                     = {978-3-642-35288-1},
  Keywords                 = {dblp}
}

@Article{breiman2001random,
  Title                    = {{Random Forests}},
  Author                   = {Breiman, Leo},
  Journal                  = {Machine Learning},
  Year                     = {2001},
  Pages                    = {5--32},
  Volume                   = {45},

  Keywords                 = {forests random}
}

@Article{breiman1996bagging,
  Title                    = {{Bagging Predictors}},
  Author                   = {Breiman, Leo},
  Journal                  = {Machine Learning},
  Year                     = {1996},
  Number                   = {421},
  Pages                    = {123--140},
  Volume                   = {24},

  Abstract                 = {Bagging predictors is a method for generating multiple versions of a pre-dictor and using these to get an aggregated predictor. The aggregation av-erages over the versions when predicting a numerical outcome and does a plurality v ote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classiication and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability o f the prediction method. If perturbing the learning set can cause signiicant changes in the predictor constructed, then bagging can improve accuracy.},
  Doi                      = {10.1007/BF00058655},
  ISBN                     = {0885-6125},
  ISSN                     = {0885-6125},
  Keywords                 = {aggregation; averaging; bootstrap; combining},
  Pmid                     = {17634459},
  Publisher                = {Springer}
}

@Book{breiman84,
  Title                    = {{Classification and regression trees}},
  Author                   = {Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  Publisher                = {CRC press},
  Year                     = {1984},

  Booktitle                = {{CA: Wadsworth International Group}},
  Doi                      = {10.1371/journal.pone.0015807},
  ISBN                     = {978-0534980535},
  ISSN                     = {19326203},
  Pmid                     = {462029}
}

@Article{burges1998tutorial,
  Title                    = {{A tutorial on support vector machines for pattern recognition}},
  Author                   = {Burges, Christopher JC},
  Journal                  = {Data mining and knowledge discovery},
  Year                     = {1998},
  Number                   = {2},
  Pages                    = {121--167},
  Volume                   = {2},

  Publisher                = {Springer}
}

@InProceedings{caruana2001overfitting,
  Title                    = {{Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping}},
  Author                   = {Caruana, Rich and Lawrence, Steve and Giles, C Lee},
  Booktitle                = {{Advances in neural information processing systems}},
  Year                     = {2001},
  Pages                    = {402--408}
}

@Article{castellano1997iterative,
  Title                    = {{An iterative pruning algorithm for feedforward neural networks}},
  Author                   = {Castellano, Giovanna and Fanelli, Anna Maria and Pelillo, Marcello},
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {1997},
  Number                   = {3},
  Pages                    = {519--531},
  Volume                   = {8},

  Owner                    = {yani},
  Publisher                = {IEEE},
  Timestamp                = {2017.09.13}
}

@InProceedings{Chang2012,
  Title                    = {{Active Attentional Sampling for Speed-up of Background Subtraction}},
  Author                   = {Chang, Hyung Jin and Jeong, Hawook and Choi, And Jin Young},
  Booktitle                = {{IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2012}
}

@InProceedings{Chen2015,
  Title                    = {{Compressing Neural Networks with the Hashing Trick}},
  Author                   = {Chen, Wenlin and Wilson, James T. and Tyree, Stephen and Weinberger, Kilian Q. and Chen, Yixin},
  Booktitle                = {{Proceedings of The 32nd International Conference on Machine Learning}},
  Year                     = {2015},
  Editor                   = {Bach, Francis R and Blei, David M},
  Pages                    = {2285--2294},
  Publisher                = {JMLR.org},
  Series                   = {{JMLR Proceedings}},
  Volume                   = {37},

  Abstract                 = {As deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very little memory and cannot store such large models. We present a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes. HashedNets uses a low-cost hash function to randomly group connection weights into hash buckets, and all connections within the same hash bucket share a single parameter value. These parameters are tuned to adjust to the HashedNets weight sharing architecture with standard backprop during training. Our hashing procedure introduces no additional memory overhead, and we demonstrate on several benchmark data sets that HashedNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1504.04788},
  Eprint                   = {1504.04788},
  ISBN                     = {9781510810587},
  Keywords                 = {dblp},
  Url                      = {http://arxiv.org/abs/1504.04788}
}

@InProceedings{Ciresan2012,
  Title                    = {{Multi-column deep neural networks for image classification}},
  Author                   = {Ciresan, Dan and Meier, Ueli and Schmidhuber, J{\"u}rgen},
  Booktitle                = {{arXiv:1202.2745v1 [cs.CV]}},
  Year                     = {2012},
  Pages                    = {3642--3649},

  Abstract                 = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winnertake-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1202.2745},
  Eprint                   = {1202.2745},
  ISBN                     = {1467312266},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.4060{&}rep=rep1{&}type=pdf{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.299.4060{&}rank=5}
}

@InProceedings{decov,
  Title                    = {{Reducing Overfitting in Deep Networks by Decorrelating Representations}},
  Author                   = {Cogswell, Michael and Ahmed, Faruk and Girshick, Ross and Zitnick, Larry and Batra, Dhruv},
  Booktitle                = {{{International Conference on Learning Representations (ICLR 2016)}, San Jose, Puerto Rico}},
  Year                     = {2016},
  Month                    = may,

  Archiveprefix            = {arXiv},
  Eprint                   = {1511.06068v4}
}

@InProceedings{Cogswell2016,
  Title                    = {{Reducing Overfitting in Deep Networks by Decorrelating Representations.}},
  Author                   = {Cogswell, Michael and Ahmed, Faruk and Girshick, Ross B and Zitnick, Larry and Batra, Dhruv},
  Booktitle                = {{International Conference on Learning Representations}},
  Year                     = {2016}
}

@Article{criminisi2013decision,
  Title                    = {{Decision Forests for Computer Vision and Medical Image Analysis}},
  Author                   = {Criminisi, Antonio and Shotton, Jamie},
  Year                     = {2013},

  Publisher                = {Springer Publishing Company, Incorporated}
}

@Article{Cryer1999,
  Title                    = {{Shape-from-shading: a survey}},
  Author                   = {Cryer, J.E. and Shah, M.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1999},
  Number                   = {8},
  Pages                    = {690--706},
  Volume                   = {21},

  Doi                      = {10.1109/34.784284},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cryer, Shah - 1999 - Shape-from-shading a survey.pdf:pdf},
  ISSN                     = {01628828},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=784284}
}

@Article{Cucchiara2001,
  Title                    = {{Improving shadow suppression in moving object detection with HSV color information}},
  Author                   = {Cucchiara, R. and Crana, C. and Piccardi, M. and Prati, a. and Sirotti, S.},
  Journal                  = {ITSC 2001. 2001 IEEE Intelligent Transportation Systems. Proceedings (Cat. No.01TH8585)},
  Year                     = {2001},
  Pages                    = {334--339},

  Doi                      = {10.1109/ITSC.2001.948679},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cucchiara et al. - 2001 - Improving shadow suppression in moving object detection with HSV color information.pdf:pdf},
  ISBN                     = {0-7803-7194-1},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=948679}
}

@Article{Cucchiara2003,
  Title                    = {{Detecting Moving Objects , Ghosts , and Shadows in Video Streams {\ae}}},
  Author                   = {Cucchiara, Rita and Grana, Costantino and Piccardi, Massimo and Prati, Andrea},
  Year                     = {2003},
  Number                   = {10},
  Pages                    = {1337--1342},
  Volume                   = {25},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cucchiara et al. - 2003 - Detecting Moving Objects , Ghosts , and Shadows in Video Streams {\ae}.pdf:pdf}
}

@InProceedings{lecun1989optimal,
  Title                    = {{Optimal Brain Damage}},
  Author                   = {LeCun, Yann and Denker, John S and Solla, Sara a},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {598--605},
  Volume                   = {2},

  Abstract                 = {We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1011.1669v3},
  Eprint                   = {arXiv:1011.1669v3},
  ISBN                     = {1558601007},
  ISSN                     = {1098-6596},
  Pmid                     = {25246403}
}

@Article{journals/mcss/Cybenko92,
  Title                    = {{Approximation by superpositions of a sigmoid function}},
  Author                   = {Cybenko, G},
  Journal                  = {Mathematics of control, signals, and systems},
  Year                     = {1989},
  Number                   = {4},
  Pages                    = {303--314},
  Volume                   = {2},

  Keywords                 = {dblp},
  Url                      = {http://dblp.uni-trier.de/db/journals/mcss/mcss5.html{\#}Cybenko92}
}

@Book{damelin2011,
  Title                    = {{The Mathematics of Signal Processing}},
  Author                   = {Damelin, Steven B. and {Miller Jr}, Willard},
  Publisher                = {Cambridge University Press},
  Year                     = {2012},

  Address                  = {Cambridge},

  Abstract                 = {Arising from courses taught by the authors, this largely self-contained treatment is ideal for mathematicians who are interested in applications or for students from applied fields who want to understand the mathematics behind their subject. Early chapters cover Fourier analysis, functional analysis, probability and linear algebra, all of which have been chosen to prepare the reader for the applications to come. The book includes rigorous proofs of core results in compressive sensing and wavelet convergence. Fundamental is the treatment of the linear system y=$\Phi$x in both finite and infinite dimensions. There are three possibilities: the system is determined, overdetermined or underdetermined, each with different aspects. The authors assume only basic familiarity with advanced calculus, linear algebra and matrix theory and modest familiarity with signal processing, so the book is accessible to students from the advanced undergraduate level. Many exercises are also included.},
  Doi                      = {10.1017/CBO9781139003896},
  ISBN                     = {9781107601048},
  Pages                    = {462},
  Pmid                     = {17238176},
  Url                      = {http://www.amazon.com/Mathematics-Signal-Processing-Cambridge-Applied/dp/1107601045/ref=pd{\_}sim{_}sbs{_}b{_}4?ie=UTF8{&}refRID=0TKKM2SWXXJPAXKE5KWG}
}

@Article{Debevec2008,
  Title                    = {{Recovering high dynamic range radiance maps from photographs}},
  Author                   = {Debevec, PE and Malik, J},
  Journal                  = {ACM SIGGRAPH 2008 classes},
  Year                     = {2008},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 1997 - Recovering High Dynamic Range Radiance Maps from Photographs Paul E . Debevec.pdf:pdf},
  Url                      = {http://dl.acm.org/citation.cfm?id=1401174}
}

@Article{DeMenthon1990,
  Title                    = {{New exact and approximate solutions of the three-point perspective problem}},
  Author                   = {DeMenthon, D and Davis, LS},
  Journal                  = {Robotics and Automation, 1990. {\ldots}},
  Year                     = {1990},
  Pages                    = {40--45},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/DeMenthon, Davis - 1990 - New exact and approximate solutions of the three-point perspective problem.pdf:pdf},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=125943}
}

@Misc{DeMenthon1992,
  Title                    = {{Exact and approximate solutions of the perspective-three-point problem}},

  Author                   = {DeMenthon, D and Davis, L S},
  Year                     = {1992},

  Abstract                 = {Model-based pose estimation techniques that match image and model triangles require large numbers of matching operations in real-world applications. The authors show that by using approximations to perspective, 2D lookup tables can be built for each of the triangles of the models. An approximation called `weak perspective' has been applied previously to this problem; the authors consider two other perspective approximations: paraperspective and orthoperspective. These approximations produce lower errors for off-center image features than weak perspective},
  Booktitle                = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}},
  Doi                      = {10.1109/34.166625},
  ISSN                     = {01628828},
  Number                   = {11},
  Pages                    = {1100--1105},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=166625},
  Volume                   = {14}
}

@InProceedings{Deng2011fastbalanced,
  Title                    = {{Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition}},
  Author                   = {Deng, J and Satheesh, S and Berg, A C and Li, F.-F.},
  Booktitle                = {{Conference and Workshop on Neural Information Processing Systems}},
  Year                     = {2011}
}

@InProceedings{Denil2013predicting,
  Title                    = {{Predicting Parameters in Deep Learning}},
  Author                   = {Denil, Misha and Shakibi, Babak and Dinh, Laurent and Ranzato, Marc'Aurelio and de Freitas, Nando},
  Booktitle                = {{Neural Information Processing Systems (NIPS)}},
  Year                     = {2013},
  Pages                    = {2148--2156},

  Abstract                 = {We demonstrate that there is signiﬁcant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95{\%} of the weights of a network without any drop in accuracy.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1306.0543},
  Eprint                   = {1306.0543},
  Url                      = {http://papers.nips.cc/paper/5025-predicting-parameters-in-deep-learning}
}

@Article{denker1987large,
  Title                    = {{Large automatic learning, rule extraction, and generalization}},
  Author                   = {Denker, John and Schwartz, Daniel and Wittner, Ben and Solla, Sara and Howard, Richard and Jackel, Lawrence and Hopfield, John},
  Journal                  = {Complex systems},
  Year                     = {1987},
  Number                   = {5},
  Pages                    = {877--922},
  Volume                   = {1}
}

@InProceedings{Denton2014efficient,
  Title                    = {{Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation}},
  Author                   = {Denton, Emily and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  Booktitle                = {{arXiv}},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {1--11},

  Abstract                 = {We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2x, while keeping the accuracy within 1{\%} of the original model.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1404.0736},
  Eprint                   = {1404.0736},
  ISSN                     = {10495258},
  Url                      = {http://arxiv.org/abs/1404.0736}
}

@Article{Drew,
  Title                    = {{Photometric stereo without multiple images 1 INTRODUCTION}},
  Author                   = {Drew, Mark S},
  Number                   = {604},
  Pages                    = {369--380},
  Volume                   = {3016},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drew - Unknown - Photometric stereo without multiple images 1 INTRODUCTION.pdf:pdf},
  Keywords                 = {based vision; color; dichromatic model; lambertian; neutral interface; physics; reflectance; shape; shape representation}
}

@Article{Edelman1998,
  Title                    = {{The geometry of algorithms with orthogonality constraints}},
  Author                   = {Edelman, A and Arias, TA},
  Journal                  = {Arxiv preprint physics/9806030},
  Year                     = {1998},

  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:physics/9806030v1},
  Eprint                   = {9806030v1},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edelman, Arias - 1998 - The geometry of algorithms with orthogonality constraints.pdf:pdf},
  Keywords                 = {15a18; 49m07; 49m15; 51f20; 53b20; 65f15; 81v55; ams subject classifications; conjugate gradient; eigenvalue optimization; eigenvalues and eigenvectors; electronic structures computation; grassmann manifold; invariant subspace; newton; orthogonality constraints; programming; rayleigh quotient iteration; reduced gradient method; s method; sequential quadratic; stiefel manifold; subspace tracking},
  Primaryclass             = {arXiv:physics},
  Url                      = {http://arxiv.org/abs/physics/9806030}
}

@InProceedings{Fahlman1989,
  Title                    = {{The Cascade-Correlation Learning Architecture}},
  Author                   = {Fahlmann, S E and Lebiere, C},
  Booktitle                = {{Advances in Neural Information Processing Systems 2}},
  Year                     = {1990},
  Editor                   = {Touretzky, David S},
  Pages                    = {524--532},
  Publisher                = {Morgan Kaufmann},

  Doi                      = {10.1190/1.1821929},
  ISBN                     = {1558601007},
  ISSN                     = {10459227},
  Pmid                     = {220943591}
}

@Misc{Fleck1995,
  Title                    = {{Perspective projection: the wrong imaging model}},

  Author                   = {Fleck, Margaret M},
  Year                     = {1995},

  Abstract                 = {Perspective projection is generally accepted as the ideal model of image formation. Many recent algorithms, and many recent judgements about the relative merits of different algorithms, depend on this assumption. However, perspective projection represents only the front half of the viewing sphere and it distorts the shape and intensity of objects unless they lie near the optical axis. It is only one of several projections used in lens design and it does not accurately model the behavior of many real lenses. It works well only for narrow-angle images. This paper surveys the properties of several alternative models of image formation. A model based on stereographic projection of the viewing sphere is shown to be a better general-purpose imaging model than perspective projection. The new model can represent wider fields of view and more closely approximates real wide-angle lenses. It preserves a suitable range of shape properties, including local symmetries. It approximates narrow-angl...},
  Booktitle                = {{Research report}},
  Pages                    = {95--01},
  Publisher                = {University of Iowa},
  Url                      = {http://www.cs.illinois.edu/{~}mfleck/my-papers/stereographic-TR.pdf}
}

@InCollection{Hertzmann2005,
  Title                    = {{Radiometry and Reflection}},
  Author                   = {Fleet, David and Hertzmann, Aaron},
  Year                     = {2005},
  Pages                    = {76--91},

  File                     = {:home/yani/Documents/LN12{\_}Lighting.pdf:pdf}
}

@Misc{fodor2002survey,
  Title                    = {{A survey of dimension reduction techniques}},

  Author                   = {Fodor, I K},
  Year                     = {2002},

  Abstract                 = {This paper, we assume that we have n observations, each being a realization of the p- dimensional random variable x = (x 1 , . . . , x p with mean E(x) = = 1 , . . . , p and covariance matrix E(x )(x = pp . We denote such an observation matrix by X = i,j : 1 p, 1 n. If i and i = (i,i) denote the mean and the standard deviation of the ith random variable, respectively, then we will often standardize the observations x i,j by (x i,j i i , where i = x i = 1/n j=1 x i,j , and i = 1/n j=1 (x i,j x i},
  Booktitle                = {{Center for Applied Scientific Computing Lawrence Livermore National Laboratory}},
  Doi                      = {10.2172/15002155},
  Pages                    = {1--18},
  Publisher                = {Technical Report UCRL-ID-148494, Lawrence Livermore National Laboratory},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.8.5098},
  Volume                   = {9}
}

@Article{frean1990upstart,
  Title                    = {The upstart algorithm: A method for constructing and training feedforward neural networks},
  Author                   = {Frean, Marcus},
  Journal                  = {Neural computation},
  Year                     = {1990},
  Number                   = {2},
  Pages                    = {198--209},
  Volume                   = {2},

  Owner                    = {yani},
  Publisher                = {MIT Press},
  Timestamp                = {2017.09.13}
}

@Article{fukushima2013artificial,
  Title                    = {{Artificial vision by multi-layered neural networks: Neocognitron and its advances}},
  Author                   = {Fukushima, Kunihiko},
  Journal                  = {Neural Networks},
  Year                     = {2013},
  Pages                    = {103--119},
  Volume                   = {37},

  Abstract                 = {The neocognitron is a neural network model proposed by. Fukushima (1980). Its architecture was suggested by neurophysiological findings on the visual systems of mammals. It is a hierarchical multi-layered network. It acquires the ability to robustly recognize visual patterns through learning. Although the neocognitron has a long history, modifications of the network to improve its performance are still going on. For example, a recent neocognitron uses a new learning rule, named add-if-silent, which makes the learning process much simpler and more stable. Nevertheless, a high recognition rate can be kept with a smaller scale of the network. Referring to the history of the neocognitron, this paper discusses recent advances in the neocognitron. We also show that various new functions can be realized by, for example, introducing top-down connections to the neocognitron: mechanism of selective attention, recognition and completion of partly occluded patterns, restoring occluded contours, and so on. {\textcopyright} 2012 Elsevier Ltd.},
  Doi                      = {10.1016/j.neunet.2012.09.016},
  ISSN                     = {08936080},
  Keywords                 = {Artificial vision; Bottom-up and top-down; Hierarchical network; Modeling neural networks; Neocognitron},
  Pmid                     = {23098752},
  Publisher                = {Elsevier}
}

@Article{Fuk80,
  Title                    = {{Neocognitron: A self-organizing neural network model for a mechanish of pattern recognition unaffected by shifts in position}},
  Author                   = {Fukushima, K},
  Journal                  = {Biological Cybernetics},
  Year                     = {1980},
  Pages                    = {193--202},
  Volume                   = {36},

  Keywords                 = {deep fukushima learning neocognitron networks neur}
}

@InProceedings{Gal2016Dropout,
  Title                    = {{Dropout as a {B}ayesian Approximation: Representing Model Uncertainty in Deep Learning}},
  Author                   = {Gal, Yarin and Ghahramani, Zoubin},
  Booktitle                = {{Proceedings of the 33rd International Conference on Machine Learning (ICML-16)}},
  Year                     = {2016}
}

@Article{Geiger2012,
  Title                    = {{Are we ready for autonomous driving? the kitti vision benchmark suite}},
  Author                   = {Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  Journal                  = {Computer Vision and},
  Year                     = {2012},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geiger, Lenz, Urtasun - 2012 - Are we ready for autonomous driving the kitti vision benchmark suite.pdf:pdf},
  Url                      = {http://h1997453.stratoserver.net/publications/cvpr12.pdf}
}

@Article{giles1987learning,
  Title                    = {{Learning, invariance, and generalization in high-order neural networks}},
  Author                   = {Giles, C Lee and Maxwell, Tom},
  Journal                  = {Applied optics},
  Year                     = {1987},
  Number                   = {23},
  Pages                    = {4972--4978},
  Volume                   = {26},

  Publisher                = {Optical Society of America}
}

@InProceedings{girshick2015deformable,
  Title                    = {{Deformable Part Models are Convolutional Neural Networks}},
  Author                   = {Girshick, Ross and Iandola, Forrest and Darrell, Trevor and Malik, Jitendra},
  Booktitle                = {{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2015},
  Pages                    = {437--446}
}

@InProceedings{glorot2010understanding,
  Title                    = {{Understanding the difficulty of training deep feedforward neural networks}},
  Author                   = {Glorot, Xavier and Bengio, Yoshua},
  Booktitle                = {{Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)}},
  Year                     = {2010},
  Pages                    = {249--256},
  Volume                   = {9},

  Abstract                 = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
  ISSN                     = {15324435},
  Url                      = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/AISTATS2010{_}GlorotB10.pdf}
}

@Article{Golovinskiy2009,
  Title                    = {{Min-cut based segmentation of point clouds}},
  Author                   = {Golovinskiy, Aleksey and Funkhouser, Thomas},
  Journal                  = {2009 IEEE 12th International Conference on Computer Vision Workshops ICCV Workshops},
  Year                     = {2009},
  Pages                    = {39--46},
  Volume                   = {150},

  Abstract                 = {We present a min-cut based method of segmenting objects in point clouds. Given an object location, our method builds a k-nearest neighbors graph, assumes a background prior, adds hard foreground (and optionally background) constraints, and finds the min-cut to compute a foreground-background segmentation. Our method can be run fully automatically, or interactively with a user interface. We test our system on an outdoor urban scan, quantitatively evaluate our algorithm on a test set of about 1000 objects, and compare to several alternative approaches.},
  Doi                      = {10.1109/ICCVW.2009.5457721},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golovinskiy, Funkhouser - 2009 - Min-cut based segmentation of point clouds.pdf:pdf},
  ISBN                     = {9781424444427},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5457721}
}

@Book{goodfellow2016deep,
  Title                    = {{Deep learning}},
  Author                   = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  Publisher                = {MIT press},
  Year                     = {2016}
}

@InProceedings{goodfellow2013maxout,
  Title                    = {{Maxout Networks}},
  Author                   = {Goodfellow, Ian J and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
  Booktitle                = {{Proceedings of the 30th International Conference on Machine Learning (ICML)}},
  Year                     = {2013},
  Pages                    = {1319--1327},
  Volume                   = {28},

  Abstract                 = {We consider the problem of designing mod-els to leverage a recently introduced ap-proximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a nat-ural companion to dropout) designed to both facilitate optimization by dropout and im-prove the accuracy of dropout's fast approxi-mate model averaging technique. We empir-ically verify that the model successfully ac-complishes both of these tasks. We use max-out and dropout to demonstrate state of the art classification performance on four bench-mark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1302.4389},
  Eprint                   = {1302.4389}
}

@Article{gorodkin1993quantitative,
  Title                    = {A quantitative study of pruning by optimal brain damage},
  Author                   = {Gorodkin, Jan and Hansen, Lars Kai and Krogh, Anders and Svarer, Claus and Winther, Ole},
  Journal                  = {International journal of neural systems},
  Year                     = {1993},
  Number                   = {02},
  Pages                    = {159--169},
  Volume                   = {4},

  Owner                    = {yani},
  Publisher                = {World Scientific},
  Timestamp                = {2017.09.13}
}

@Article{Gortler1996,
  Title                    = {{The lumigraph}},
  Author                   = {Gortler, Steven J. and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael F.},
  Journal                  = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques - SIGGRAPH '96},
  Year                     = {1996},
  Pages                    = {43--54},

  Address                  = {New York, New York, USA},
  Doi                      = {10.1145/237170.237200},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gortler et al. - 1996 - The lumigraph.pdf:pdf},
  ISBN                     = {0897917464},
  Publisher                = {ACM Press},
  Url                      = {http://portal.acm.org/citation.cfm?doid=237170.237200}
}

@InProceedings{Gupta2015,
  Title                    = {{Deep Learning with Limited Numerical Precision}},
  Author                   = {Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  Booktitle                = {{Proceedings of the 32nd International Conference on Machine Learning (ICML-15)}},
  Year                     = {2015},
  Editor                   = {Blei, David and Bach, Francis},
  Pages                    = {1737--1746},
  Publisher                = {JMLR Workshop and Conference Proceedings}
}

@Misc{1502.02551v1,
  Title                    = {{Deep Learning with Limited Numerical Precision}},

  Author                   = {Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  Month                    = feb,
  Year                     = {2015},

  Abstract                 = {Training of large-scale deep neural networks is often constrained by the available computational resources. We study the effect of limited preci- sion data representation and computation on neu- ral network training. Within the context of low- precision fixed-point computations, we observe the rounding scheme to play a crucial role in de- termining the network's behavior during train- ing. Our results show that deep networks can be trained using only 16-bit wide fixed-point num- ber representation when using stochastic round- ing, and incur little to no degradation in the classification accuracy. We also demonstrate an energy-efficient hardware accelerator that imple- ments low-precision fixed-point arithmetic with stochastic rounding.},
  Annote                   = {published = 2015-02-09T16:37:29Z, updated = 2015-02-09T16:37:29Z, 10 pages, 6 figures, 1 table},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1502.02551},
  Booktitle                = {{Proceedings of the 32nd International Conference on Machine Learning (ICML-15)}},
  Doi                      = {10.1109/72.80206},
  Eprint                   = {1502.02551},
  ISBN                     = {9781510810587},
  ISSN                     = {19410093},
  Pages                    = {1737--1746},
  Pmid                     = {18282824},
  Url                      = {http://jmlr.org/proceedings/papers/v37/gupta15.pdf}
}

@InProceedings{hypernetworks,
  Title                    = {{HyperNetworks}},
  Author                   = {Ha, David and Dai, Andrew and Le, Quoc V.},
  Booktitle                = {{International Conference on Learning Representations (ICLR), Toulon, France}},
  Year                     = {2017}
}

@Article{han2015deep,
  Title                    = {{Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding}},
  Author                   = {Han, Song and Mao, Huizi and Dally, William J},
  Year                     = {2016},

  Booktitle                = {{International Conference on Learning Representations (ICLR), San Juan, Puerto Rico}}
}

@InProceedings{han2016dsd,
  Title                    = {{Dsd: Dense-sparse-dense training for deep neural networks}},
  Author                   = {Han, Song and Pool, Jeff and Narang, Sharan and Mao, Huizi and Gong, Enhao and Tang, Shijian and Elsen, Erich and Vajda, Peter and Paluri, Manohar and Tran, John and others},
  Booktitle                = {{International Conference on Learning Representations (ICLR), Toulon, France}},
  Year                     = {2017}
}

@InProceedings{han2015learning,
  Title                    = {{Learning both weights and connections for efficient neural network}},
  Author                   = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2015},
  Pages                    = {1135--1143},

  Owner                    = {yani},
  Timestamp                = {2017.09.13}
}

@Article{journals/iandc/HancockJLT96,
  Title                    = {{Lower Bounds on Learning Decision Lists and Trees}},
  Author                   = {Hancock, Thomas and Jiang, Tao and Li, Ming and Tromp, John},
  Journal                  = {Information and Computation},
  Year                     = {1996},
  Number                   = {2},
  Pages                    = {114--122},
  Volume                   = {126},

  Abstract                 = {k-Decision lists and decision trees play important roles in learning theory as well as in practical learning systems.k-Decision lists generalize classes such as monomials,k-DNF, andk-CNF, and like these subclasses they are polynomially PAC-learnable [R. Rivest,Mach. Learning2(1987), 229--246]. This leaves open the question of whetherk-decision lists can be learned as efficiently ask-DNF. We answer this question negatively in a certain sense, thus disproving a claim in a popular textbook [M. Anthony and N. Biggs, ``Computational Learning Theory,'' Cambridge Univ. Press, Cambridge, UK, 1992]. Decision trees, on the other hand, are not even known to be polynomially PAC-learnable, despite their widespread practical application. We will show that decision trees are not likely to be efficiently PAC-learnable. We summarize our specific results. The following problems cannot be approximated in polynomial time within a factor of 2log$\delta$ nfor any$\delta${\textless}1, unlessNP⊂DTIME[2polylog n]: a generalized set cover,k-decision lists,k-decision lists by monotone decision lists, and decision trees. Decision lists cannot be approximated in polynomial time within a factor ofn$\delta$, for some constant$\delta${\textgreater}0, unlessNP=P. Also,k-decision lists withl0--1 alternations cannot be approximated within a factor logl nunlessNP⊂DTIME[nO(log log n)] (providing an interesting comparison to the upper bound obtained by A. Dhagat and L. Hellerstein [in``FOCS '94,'' pp. 64--74]).},
  Doi                      = {10.1006/inco.1996.0040},
  ISBN                     = {3540590420},
  ISSN                     = {0890-5401},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0890540196900401{\%}5Cnhttp://www.sciencedirect.com/science/article/pii/S0890540196900401/pdf?md5=59bdd8c077309262836d57b76a5a5577{&}pid=1-s2.0-S0890540196900401-main.pdf}
}

@Misc{Hanmandlu2000,
  Title                    = {{Depth estimation from a sequence of images using spherical projection}},

  Author                   = {Hanmandlu, M and Shantaram, V and Sudheer, K},
  Year                     = {2000},

  Abstract                 = {A recursive estimation of depth from a sequence of images is proposed. Using the spherical projection, a simple equation is derived that relates image motion with the object motion. This equation is reformulated into a dynamical state space model for which Kalman filter can be easily applied to yield the estimate of depth. Point correspondences have been used to obtain feature points and the motion parameters are assumed to be known. The results are illustrated on a real object},
  Booktitle                = {{Proceedings of International Conference on Robotics and Automation}},
  Doi                      = {10.1109/ITCC.2000.844211},
  ISBN                     = {0769505406},
  Number                   = {April},
  Pages                    = {2264--2269},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=619298},
  Volume                   = {3}
}

@InProceedings{hanson1989comparing,
  Title                    = {{Comparing biases for minimal network construction with back-propagation}},
  Author                   = {Hanson, Stephen Jos{\'e} and Pratt, Lorien Y},
  Booktitle                = {{Advances in neural information processing systems}},
  Year                     = {1989},
  Pages                    = {177--185}
}

@Article{Happel1994,
  Title                    = {{Design and evolution of modular neural network architectures.}},
  Author                   = {Happel, Bart L M and Murre, Jacob M J},
  Journal                  = {Neural Networks},
  Year                     = {1994},
  Number                   = {6-7},
  Pages                    = {985--1004},
  Volume                   = {7}
}

@Article{Haralick1989,
  Title                    = {{Monocular vision using inverse perspective projection geometry: analytic relations}},
  Author                   = {Haralick, R M},
  Journal                  = {Proceedings CVPR 89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  Year                     = {1989},
  Pages                    = {370--378},
  Volume                   = {10},

  Doi                      = {10.1109/CVPR.1989.37874},
  ISBN                     = {081861918X},
  Publisher                = {IEEE Comput. Soc. Press},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=37874}
}

@InProceedings{Hardt2015,
  Title                    = {{Train faster, generalize better: Stability of stochastic gradient descent}},
  Author                   = {Hardt, Moritz and Recht, Benjamin and Singer, Yoram},
  Booktitle                = {{Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)}},
  Year                     = {2015},

  Address                  = {New York, New York, USA},
  Pages                    = {1--24},

  Abstract                 = {We show that any model trained by a stochastic gradient method with few iterations has vanishing generalization error. We prove this by showing the method is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. Our results apply to both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. Applying our results to the convex case, we provide new explanations for why multiple epochs of stochastic gradient descent generalize well in practice. In the nonconvex case, we provide a new interpretation of common practices in neural networks, and provide a formal rationale for stability-promoting mechanisms in training large, deep models. Conceptually, our findings underscore the importance of reducing training time beyond its obvious benefit.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1509.01240},
  Eprint                   = {1509.01240},
  ISBN                     = {9781510829008}
}

@Article{Hasinoff2010,
  Title                    = {{Noise-optimal capture for high dynamic range photography}},
  Author                   = {Hasinoff, Samuel W. and Durand, Fredo and Freeman, William T.},
  Journal                  = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  Year                     = {2010},

  Month                    = {jun},
  Pages                    = {553--560},

  Doi                      = {10.1109/CVPR.2010.5540167},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hasinoff, Durand, Freeman - 2010 - Noise-optimal capture for high dynamic range photography.pdf:pdf},
  ISBN                     = {978-1-4244-6984-0},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5540167}
}

@Book{haykin1994neural,
  Title                    = {Neural networks: a comprehensive foundation},
  Author                   = {Haykin, Simon},
  Publisher                = {Prentice Hall PTR},
  Year                     = {1994}
}

@InProceedings{He2012,
  Title                    = {{Incremental Gradient on the Grassmannian for Online Foreground and Background Separation in Subsampled Video}},
  Author                   = {He, Jun and Balzano, Laura and Szlam, Arthur},
  Year                     = {2012},
  Pages                    = {1568--1575},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Balzano, Szlam - 2012 - Incremental Gradient on the Grassmannian for Online Foreground and Background Separation in Subsampled Video.pdf:pdf},
  ISBN                     = {9781467312288}
}

@InProceedings{he2015convolutional,
  Title                    = {{Convolutional Neural Networks at Constrained Time Cost}},
  Author                   = {He, Kaiming and Sun, Jian},
  Booktitle                = {{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2015},
  Pages                    = {5353--5360}
}

@Article{He2016,
  Title                    = {{Identity Mappings in Deep Residual Networks}},
  Author                   = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  Journal                  = {arXiv preprint},
  Year                     = {2016},
  Pages                    = {1--15},
  Volume                   = {abs/1603.0},

  Abstract                 = {Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which further makes training easy and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10/100, and a 200-layer ResNet on ImageNet.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1603.05027},
  Eprint                   = {1603.05027},
  Url                      = {http://arxiv.org/abs/1603.05027}
}

@Article{He2015,
  Title                    = {{Deep Residual Learning for Image Recognition}},
  Author                   = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  Journal                  = {Arxiv.Org},
  Year                     = {2015},
  Number                   = {3},
  Pages                    = {171--180},
  Volume                   = {7},

  Abstract                 = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8× deeper than VGG nets [41] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28{\%} relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1512.03385},
  Doi                      = {10.3389/fpsyg.2013.00124},
  Eprint                   = {1512.03385},
  ISBN                     = {978-1-4673-6964-0},
  ISSN                     = {1664-1078},
  Keywords                 = {deep learning; denoising auto-encoder; image denoising},
  Pmid                     = {23554596},
  Url                      = {http://arxiv.org/pdf/1512.03385v1.pdf}
}

@InProceedings{He2015b,
  Title                    = {{Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}},
  Author                   = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  Booktitle                = {{IEEE Conference on Computer Vision and Patern Recognition (ICCV)}},
  Year                     = {2015},
  Pages                    = {1026--1034},
  Publisher                = {IEEE},

  Abstract                 = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra com-putational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94{\%} top-5 test error on the ImageNet 2012 clas-sification dataset. This is a 26{\%} relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66{\%} [33]). To our knowledge, our result is the first 1 to surpass the reported human-level performance (5.1{\%}, [26]) on this dataset.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1502.01852},
  Doi                      = {10.1109/ICCV.2015.123},
  Eprint                   = {1502.01852},
  ISBN                     = {978-1-4673-8391-2},
  ISSN                     = {15505499},
  Keywords                 = {dblp}
}

@Article{ieee7005506,
  Title                    = {{Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}},
  Author                   = {He, K and Zhang, X and Ren, S and Sun, J},
  Journal                  = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  Year                     = {2015},
  Number                   = {99},
  Pages                    = {1},
  Volume                   = {PP},

  Abstract                 = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224224) input image. This requirement is ``artificial'' and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, ``spatial pyramid pooling'', to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-theart classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank {\#}2 in object detection and {\#}3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
  Doi                      = {10.1109/TPAMI.2015.2389824},
  ISSN                     = {0162-8828},
  Keywords                 = {Accuracy; Agriculture; Convolutional codes; Featur}
}

@Article{helearning,
  Title                    = {{Learning Visual Features for Outdoor Localization}},
  Author                   = {He, X and Mnih, V and Ioannou, Y and Zemel, R S}
}

@Article{Healey1994,
  Title                    = {{Radiometric CCD camera calibration and noise estimation}},
  Author                   = {Healey, Glenn E and Kondepudy, Raghava and Member, Student},
  Journal                  = {Pattern Analysis and Machine {\ldots}},
  Year                     = {1994},
  Number                   = {3},
  Volume                   = {16},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Healey, Kondepudy, Member - 1994 - Radiometric CCD camera calibration and noise estimation.pdf:pdf},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=276126}
}

@Book{hebb1949organization,
  Title                    = {{The organization of behavior: A neuropsychological approach}},
  Author                   = {Hebb, Donald Olding},
  Publisher                = {John Wiley \& Sons},
  Year                     = {1949}
}

@Misc{dropoutsurprising,
  Title                    = {{Surprising properties of dropout in deep networks}},

  Author                   = {Helmbold, David P. and Long, Philip M.},
  Month                    = nov,
  Year                     = {2016},

  Archiveprefix            = {arXiv},
  Eprint                   = {1602.04484},
  Primaryclass             = {cs.LG}
}

@Article{Himmelsbach2008,
  Title                    = {{LIDAR-based 3D object perception}},
  Author                   = {Himmelsbach, M},
  Journal                  = {Proceedings of 1st},
  Year                     = {2008},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Himmelsbach - 2008 - LIDAR-based 3D object perception.pdf:pdf},
  Url                      = {http://www.cs.princeton.edu/courses/archive/spring11/cos598A/pdfs/Himmelsbach08.pdf}
}

@InProceedings{hinton1987learning,
  Title                    = {{Learning translation invariant recognition in a massively parallel networks}},
  Author                   = {Hinton, GE and de Bakker, JW},
  Booktitle                = {{Proceedings of the Conference on Parallel Architectures and Languages Europe (PARLE)}},
  Year                     = {1987},
  Organization             = {Springer},
  Pages                    = {1--13}
}

@Misc{HintonTalk2015,
  Title                    = {{Deep Learning}},

  Author                   = {Hinton, Geoffery E.},
  HowPublished             = {Public Lecture},
  Month                    = jun,
  Year                     = {2015},

  Institution              = {Department of Engineering},
  Location                 = {University of Cambridge},
  Series                   = {{Division F Talks}},
  Url                      = {http://sms.cam.ac.uk/media/2017973}
}

@Article{hinton2006reducing,
  Title                    = {{Reducing the Dimensionality of Data with Neural Networks$\backslash$r}},
  Author                   = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  Journal                  = {Science},
  Year                     = {2006},
  Number                   = {5786},
  Pages                    = {504--507},
  Volume                   = {313},

  Abstract                 = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural$\backslash$rnetwork with a small central layer to reconstruct high-dimensional input vectors. Gradient descent$\backslash$r$\backslash$ncan be used for fine-tuning the weights in such {\lq}{\lq}autoencoder'' networks, but this works well only if$\backslash$r$\backslash$nthe initial weights are close to a good solution. We describe an effective way of initializing the$\backslash$r$\backslash$nweights that allows deep autoencoder networks to learn low-dimensional codes that work much$\backslash$r$\backslash$nbetter than principal components analysis as a tool to reduce the dimensionality of data.$\backslash$r$\backslash$n},
  Archiveprefix            = {arXiv},
  Arxivid                  = {20},
  Doi                      = {10.1126/science.1127647},
  Eprint                   = {20},
  ISSN                     = {1095-9203},
  Pmid                     = {16873662},
  Publisher                = {American Association for the Advancement of Science}
}

@Misc{Hinton2012,
  Title                    = {{Improving neural networks by preventing co-adaptation of feature detectors}},

  Author                   = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
  Month                    = jul,
  Year                     = {2012},

  Abstract                 = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1207.0580},
  Booktitle                = {{ArXiv e-prints}},
  Eprint                   = {1207.0580},
  ISBN                     = {9781467394673},
  ISSN                     = {9781467394673},
  Pages                    = {1--18},
  Pmid                     = {1000104337},
  Url                      = {http://arxiv.org/abs/1207.0580}
}

@PhdThesis{hochreiter1991untersuchungen,
  Title                    = {{Untersuchungen zu dynamischen neuronalen Netzen}},
  Author                   = {Hochreiter, Sepp},
  School                   = {Technische Universit{\{}{\"a}{\}}t M{\{}{\"u}{\}}nchen},
  Year                     = {1991},

  Booktitle                = {{Diploma, Technische Universit{\{}{\"a}{\}}t M{\{}{\"u}{\}}nchen}},
  Pages                    = {91}
}

@Misc{Hochreiter01gradientflow,
  Title                    = {{Gradient flow in recurrent nets: the difficulty of learning long-term dependencies}},

  Author                   = {Hochreiter, Sepp and Bengio, Y and Frasconi, Paolo and Schmidhuber, J},
  Year                     = {2001},

  Abstract                 = {Introduction Recurrent networks (crossreference Chapter 12) can, in principle, use their feedback connections to store representations of recent input events in the form of activations. The most widely used algorithms for learning what to put in short-term memory, however, take too much time to be feasible or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long. Although theoretically fascinating, they do not provide clear practical advantages over, say, backprop in feedforward networks with limited time windows (see crossreference Chapters 11 and 12). With conventional {\&}034;algorithms based on the computation of the complete gradient{\&}034;, such as {\&}034;Back-Propagation Through Time{\&}034; (BPTT, e.g., 22, 27, 26) or {\&}034;Real-Time Recurrent Learning{\&}034; (RTRL, e.g., 21) error signals {\&}034;flowing backwards in time{\&}034; tend to either (1) blow up or (2) vanish: the temporal evolution of the backpropagated error ex},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1011.1669v3},
  Booktitle                = {{A Field Guide to Dynamical Recurrent Networks}},
  Doi                      = {10.1109/9780470544037.ch14},
  Eprint                   = {arXiv:1011.1669v3},
  ISBN                     = {978-0-7803-5369-5},
  ISSN                     = {1098-6596},
  Pages                    = {237--243},
  Pmid                     = {25246403},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.7321{&}rep=rep1{&}type=pdf}
}

@Article{Horn1974,
  Title                    = {{Determining lightness from an image}},
  Author                   = {Horn, BKP},
  Journal                  = {Computer Graphics and Image Processing},
  Year                     = {1974},

  File                     = {:home/yani/Documents/On{\_}Lightness{\_}OCR.pdf:pdf},
  Url                      = {http://www.sciencedirect.com/science/article/pii/0146664X74900227}
}

@Article{Horn1979,
  Title                    = {{Calculating the reflectance map.}},
  Author                   = {Horn, B K and Sjoberg, R W},
  Journal                  = {Applied Optics},
  Year                     = {1979},
  Number                   = {11},
  Pages                    = {1770--1779},
  Volume                   = {18},

  Abstract                 = {It appears that the development of machine vision may benefit from a detailed understanding of the imaging process. The reflectance map, showing scene radiance as a function of surface gradient, has proved to be helpful in this endeavor. The reflectance map depends both on the nature of the surface layers of the objects being imaged and the distribution of light sources. Recently, a unified approach to the specification of surface reflectance in terms of both incident and reflected beam geometry has been proposed. The reflecting properties of a surface are specified in terms of the bidirectional reflectance-distribution function (BRDF). Here we derive the reflectance map in terms of the BRDF and the distribution of source radiance. A number of special cases of practical importance are developed in detail. The significance of this approach to the understanding of image formation is briefly indicated.},
  Doi                      = {10.1364/AO.18.001770},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horn, Sjoberg - 1979 - Calculating the reflectance map.pdf:pdf},
  Keywords                 = {image brightness; scene brightness; surface reflec},
  Pmid                     = {20212547},
  Publisher                = {OSA},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/20212547}
}

@Article{Horn1990,
  Title                    = {{Height and Gradient from Shading}},
  Author                   = {Horn, B K P},
  Journal                  = {The International Journal of Computer Vision},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {37--75},
  Volume                   = {5},

  Abstract                 = {The method described here for recovering the shape of a surface from a shaded image can deal with complex, wrinkled surfaces. Integrability can be enforced easily because both surface height and gradient are represented. (A gradient field is integrable if it is the gradient of some surface height function.) The robustness of the method stems in part from linearization of the reflectance map about the current estimate of the surface orientation at each picture cell. (The reflectance map gives the dependence of scene radiance on surface orientation.) The new scheme can find an exact solution of a given shape-from-shading problem even though a regularizing term is included. The reason is that the penalty term is needed only to stabilize the iterative scheme when it is far from the correct solution; it can be turned off as the solution is approached. This is a reflection of the fact that shape-from-shading problems are not ill posed when boundary conditions are available, or when the image contains singular points.},
  Doi                      = {10.1007/bf00056771},
  ISSN                     = {09205691},
  Publisher                = {Springer Netherlands},
  Url                      = {http://www.springerlink.com/index/L90617LKGL701386.pdf}
}

@Article{Horn1977,
  Title                    = {{Understanding Image Intensities}},
  Author                   = {Horn, Berthold K P},
  Journal                  = {Artificial Intelligence},
  Year                     = {1977},
  Number                   = {2},
  Pages                    = {201--231},
  Volume                   = {8},

  Abstract                 = {Traditionally, image intensities have been processed to segment an image into regions or to find edge-fragments. Image intensities carry a great deal more information about three-dimensional shape, however. To exploit this information, it is necessary to understand how images are formed and what determines the observed intensity in the image. The gradient space, popularized by Huffman and Mackworth in a slightly different context, is a helpful tool in the development of new methods.},
  Doi                      = {10.1016/0004-3702(77)90020-0},
  File                     = {:home/yani/Documents/1-s2.0-0004370277900200-main.pdf:pdf},
  ISSN                     = {00043702},
  Url                      = {http://linkinghub.elsevier.com/retrieve/pii/0004370277900200}
}

@Misc{Horn1970,
  Title                    = {{Shape from Shading: A Method for Obtaining the Shape of a Smooth Opaque Object from One View}},

  Author                   = {Horn, Berthold K P},
  Year                     = {1970},

  Abstract                 = {A method will be described for finding the shape of a smooth apaque object form a monocular image, given a knowledge of the surface photometry, the position of the lightsource and certain auxiliary information to resolve ambiguities. This method is complementary to the use of stereoscopy which relies on matching up sharp detail and will fail on smooth objects. Until now the image processing of single views has been restricted to objects which can meaningfully be considered two-dimensional or bounded by plane surfaces. It is possible to derive a first-order non-linear partial differential equation in two unknowns relating the intensity at the image points to the shape of the objects. This equation can be solved by means of an equivalent set of five ordinary differential equations. A curve traced out by solving this set of equations for one set of starting values is called a characteristic strip. Starting one of these strips from each point on some initial curve will produce the whole solution surface. The initial curves can usually be constructed around so-called singular points. A number of applications of this metod will be discussed including one to lunar topography and one to the scanning electron microscope. In both of these cases great simplifications occur in the equations. A note on polyhedra follows and a quantitative theory of facial make-up is touched upon. An implementation of some of these ideas on the PDP-6 computer with its attached image-dissector camera at the Artificial intelligence Laboratory will be described, and also a nose-recognition program.},
  Booktitle                = {{Doctor}},
  Institution              = {MIT Artificial Intelligence Laboratory},
  Number                   = {232},
  Pages                    = {196},
  Url                      = {http://dspace.mit.edu/handle/1721.1/6885}
}

@Article{hornik89a,
  Title                    = {{Multilayer feedforward networks are universal approximators}},
  Author                   = {Hornik, K and Stinchcombe, M and White, H},
  Journal                  = {Neural Networks},
  Year                     = {1989},
  Pages                    = {356--366},
  Volume                   = {2},

  Abstract                 = {Thesis BIB},
  Keywords                 = {imported}
}

@Article{Horprasert1999,
  Title                    = {{A statistical approach for real-time robust background subtraction and shadow detection}},
  Author                   = {Horprasert, Thanarat and Harwood, David},
  Journal                  = {IEEE ICCV},
  Year                     = {1999},
  Pages                    = {1--19},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horprasert, Harwood - 1999 - A statistical approach for real-time robust background subtraction and shadow detection.pdf:pdf},
  Url                      = {http://vast.uccs.edu/{~}tboult/frame/Horprasert/}
}

@Article{Hubel1959a,
  Title                    = {{Receptive fields of single neurones in the cat's striate cortex.}},
  Author                   = {Hubel, D H and Wiesel, T N},
  Journal                  = {Journal of Physiology},
  Year                     = {1959},
  Pages                    = {574--591},
  Volume                   = {148},

  Abstract                 = {Recordings were made in lightly anaesthesized cats whose retinas were stimulated, singly or together, with light spots of various sizes and shapes. Receptive fields, defined as restricted areas where illumination influenced the firing of a single cortical unit, usually contained mutually antagonistic excitatory and inhibitory regions. Thus a stimulus covering a whole field was relatively ineffective in driving most units. Effective driving of a unit required a stimulus specific in form, size, position, and orientation; based on the arrangement of excitatory and inhibitory areas. About 20{\%} of the cortical units studied could be activated from either eye; these were driven from roughly homologous regions of the retinas and summation and antagonism could be shown. (PsycINFO Database Record (c) 2009 APA, all rights reserved)},
  Doi                      = {10.1113/jphysiol.2009.174151},
  ISSN                     = {00223751},
  Keywords                 = {CEREBRAL CORTEX/physiology; NEURONS/physiology},
  Pmid                     = {14403679},
  Url                      = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed{&}id=14403679{&}retmode=ref{&}cmd=prlinks}
}

@Article{Humenberger2012,
  Title                    = {{Embedded Fall Detection with a Neural Network and Bio-Inspired Stereo Vision}},
  Author                   = {Humenberger, Martin and Schraml, Stephan and Sulzbachner, Christoph and Belbachir, Ahmed Nabil},
  Year                     = {2012},
  Pages                    = {60--67},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Humenberger et al. - 2012 - Embedded Fall Detection with a Neural Network and Bio-Inspired Stereo Vision.pdf:pdf},
  ISBN                     = {9781467316125}
}

@Article{Hwang2011,
  Title                    = {{Difference-based Image Noise Modeling Using Skellam Distribution.}},
  Author                   = {Hwang, Youngbae and Kim, Jun-Sik and Kweon, In So},
  Journal                  = {IEEE transactions on pattern analysis and machine intelligence},
  Year                     = {2011},

  Month                    = {nov},
  Number                   = {7},
  Pages                    = {1329--1341},
  Volume                   = {34},

  Abstract                 = {By the laws of quantum physics, pixel intensity does not have a true value, but should be a random variable. Contrary to the conventional assumptions, the distribution of intensity may not be an additive Gaussian. We propose to directly model the intensity difference, and show its validity by an experimental comparison to the conventional additive model. As a model of the intensity difference, we present a Skellam distribution derived from the Poisson photon noise model. This modeling induces a linear relationship between intensity and Skellam parameters, while conventional variance computation methods do not yield any significant relationship between these parameters under natural illumination. The intensity-Skellam line is invariant to scene, illumination and even most of camera parameters. We also propose practical methods to obtain the line using a color pattern and an arbitrary image under a natural illumination. Because the Skellam parameters that can be obtained from this linearity determine a noise distribution for each intensity value, we can statistically determine whether any intensity difference is caused by an underlying signal difference or by noise. We demonstrate the effectiveness of this new noise model by applying it to practical applications of background subtraction and edge detection.},
  Doi                      = {10.1109/TPAMI.2011.224},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hwang, Kim, Kweon - 2011 - Difference-based Image Noise Modeling Using Skellam Distribution.pdf:pdf},
  ISSN                     = {1939-3539},
  Pmid                     = {22144520},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/22144520}
}

@Article{Hyvarinen2000,
  Title                    = {{Independent component analysis: algorithms and applications.}},
  Author                   = {Hyv{\"a}rinen, A and Oja, E},
  Journal                  = {Neural Networks},
  Year                     = {2000},
  Number                   = {4-5},
  Pages                    = {411--430},
  Volume                   = {13},

  Abstract                 = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyv{\"a}rinen, Oja - 2000 - Independent component analysis algorithms and applications.pdf:pdf},
  Institution              = {Neural Networks Research Centre, Helsinki University of Technology, Finland. aapo.hyvarinen@hut.fi},
  Keywords                 = {algorithms; artifacts; brain; brain physiology; humans; magnetoencephalography; neural networks (computer); normal distribution},
  Pmid                     = {10946390},
  Publisher                = {Elsevier},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/10946390}
}

@Article{I-lealey,
  Title                    = {{CCD Camera Calibration and Noise Estimation}},
  Author                   = {I-lealey, Glenn and Kondepudy, Raghava},
  Number                   = {5},
  Pages                    = {90--95},
  Volume                   = {92717},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/I-lealey, Kondepudy - Unknown - CCD Camera Calibration and Noise Estimation.pdf:pdf},
  ISBN                     = {0818628553}
}

@Article{Ioannou2010,
  Title                    = {{Automatic urban modelling using mobile urban lidar data}},
  Author                   = {Ioannou, Yani Andrew},
  Journal                  = {Thesis (Master, Computing), Queen's University},
  Year                     = {2010},
  Number                   = {February},

  Abstract                 = {Recent advances in Light Detection and Ranging (LIDAR) technology and integration have resulted in vehicle-borne platforms for urban LIDAR scanning, such as Terrapoint Inc.'s TITAN system. Such technology has lead to an explosion in ground LIDAR data. The large size of such mobile urban LIDAR data sets, and the ease at which they may now be collected, has shifted the bottleneck of creating abstract urban models for Geographical Information Systems (GIS) from data collection to data processing. While turning such data into useful models has traditionally relied on human analysis, this is no longer practical. This thesis outlines a methodology for automatically recovering the necessary information to create abstract urban models from mobile urban LIDAR data using computer vision methods. As an integral part of the methodology, a novel scale-based interest operator is introduced (Difference of Normals) that is efficient enough to process large datasets, while accurately isolating objects of interest in the scene according to real-world parameters. Finally a novel localized object recognition algorithm is introduced (Local Potential Well Space Embedding), derived from a proven global method for object recognition (Potential Well Space Embedding). The object recognition phase of our methodology is discussed with these two algorithms as a focus.},
  Keywords                 = {LIDAR; point clouds; GIS; computer vision; urban},
  Mendeley-tags            = {LIDAR, point clouds, GIS, computer vision, urban},
  Url                      = {http://qspace.library.queensu.ca/handle/1974/5443}
}

@InProceedings{ioannou2016e,
  Title                    = {{Deep Roots: Improving CNN efficiency with hierarchical filter groups}},
  Author                   = {Ioannou, Yani and Robertson, Duncan and Cipolla, Roberto and Criminisi, Antonio},
  Booktitle                = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017, Honolulu, Hawaii}},
  Year                     = {2016},

  Abstract                 = {We propose a new method for training computationally efficient and compact convolutional neural networks (CNNs) using a novel sparse connection structure that resembles a tree root. Our sparse connection structure facilitates a significant reduction in computational cost and number of parameters of state-of-the-art deep CNNs without compromising accuracy. We validate our approach by using it to train more efficient variants of state-of-the-art CNN architectures, evaluated on the CIFAR10 and ILSVRC datasets. Our results show similar or higher accuracy than the baseline architectures with much less compute, as measured by CPU and GPU timings. For example, for ResNet 50, our model has 40{\%} fewer parameters, 45{\%} fewer floating point operations, and is 31{\%} (12{\%}) faster on a CPU (GPU). For the deeper ResNet 200 our model has 25{\%} fewer floating point operations and 44{\%} fewer parameters, while maintaining state-of-the-art accuracy. For GoogLeNet, our model has 7{\%} fewer parameters and is 21{\%} (16{\%}) faster on a CPU (GPU).},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1605.06489},
  Eprint                   = {1605.06489}
}

@InProceedings{Ioannou2016c,
  Title                    = {{Training CNNs with Low-Rank Filters for Efficient Image Classification}},
  Author                   = {Ioannou, Yani and Robertson, Duncan and Shotton, Jamie and Cipolla, Roberto and Criminisi, Antonio},
  Booktitle                = {{International Conference on Learning Representations 2016 (ICLR), San Juan, Puerto Rico}},
  Year                     = {2016},
  Month                    = {may},

  Abstract                 = {We propose a new method for creating computationally efficient convolutional neural networks (CNNs) by using low-rank representations of convolutional filters. Rather than approximating filters in previously-trained networks with more efficient versions, we learn a set of small basis filters from scratch; during training, the network learns to combine these basis filters into more complex filters that are discriminative for image classification. To train such networks, a novel weight initialization scheme is used. This allows effective initialization of connection weights in convolutional layers composed of groups of differently-shaped filters. We validate our approach by applying it to several existing CNN architectures and training these networks from scratch using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or higher accuracy than conventional CNNs with much less compute. Applying our method to an improved version of VGG-11 network using global max-pooling, we achieve comparable validation accuracy using 41{\%} less compute and only 24{\%} of the original VGG-11 model parameters; another variant of our method gives a 1 percentage point increase in accuracy over our improved VGG-11 model, giving a top-5 center-crop validation accuracy of 89.7{\%} while reducing computation by 16{\%} relative to the original VGG-11 model. Applying our method to the GoogLeNet architecture for ILSVRC, we achieved comparable accuracy with 26{\%} less compute and 41{\%} fewer model parameters. Applying our method to a near state-of-the-art network for CIFAR, we achieved comparable accuracy with 46{\%} less compute and 55{\%} fewer parameters.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1511.06744},
  Eprint                   = {1511.06744},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioannou et al. - 2016 - TRAINING CNNS WITH LOW-RANK FILTERS FOR EFFICIENT IMAGE CLASSIFICATION.pdf:pdf},
  Keywords                 = {Deep Learning; Efficient; Low-rank; Separable},
  Mendeley-tags            = {Deep Learning,Efficient,Low-rank,Separable},
  Url                      = {http://arxiv.org/abs/1511.06744}
}

@TechReport{Ioannou2015,
  Title                    = {{Decision Forests, Convolutional Networks and the Models in-Between}},
  Author                   = {Ioannou, Yani and Robertson, Duncan and Zikic, Darko and Kontschieder, Peter and Shotton, Jamie and Brown, Matthew and Criminisi, Antonio},
  Institution              = {Microsoft Research},
  Year                     = {2015},
  Month                    = apr,
  Number                   = {MSR-TR-2015-58},

  Booktitle                = {{Technical Report}}
}

@TechReport{Ioannou2016d,
  Title                    = {{Decision Forests, Convolutional Networks and the Models in-Between}},
  Author                   = {Ioannou, Yani and Robertson, Duncan and Zikic, Darko and Kontschieder, Peter and Shotton, Jamie and Brown, Matthew and Criminisi, Antonio},
  Year                     = {2015},
  Month                    = {apr},

  Abstract                 = {This paper investigates the connections between two state of the art classifiers: decision forests (DFs, including decision jungles) and convolutional neural networks (CNNs). Decision forests are computationally efficient thanks to their conditional computation property (computation is confined to only a small region of the tree, the nodes along a single branch). CNNs achieve state of the art accuracy, thanks to their representation learning capabilities. We present a systematic analysis of how to fuse conditional computation with representation learning and achieve a continuum of hybrid models with different ratios of accuracy vs. efficiency. We call this new family of hybrid models conditional networks. Conditional networks can be thought of as: i) decision trees augmented with data transformation operators, or ii) CNNs, with block-diagonal sparse weight matrices, and explicit data routing functions. Experimental validation is performed on the common task of image classification on both the CIFAR and Imagenet datasets. Compared to state of the art CNNs, our hybrid models yield the same accuracy with a fraction of the compute cost and much smaller number of parameters.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1603.01250},
  Booktitle                = {{Microsoft Research Technical Report}},
  Eprint                   = {1603.01250},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioannou et al. - 2015 - Decision Forests, Convolutional Networks and the Models in-Between.pdf:pdf},
  Keywords                 = {CNN; Decision Forests; Deep Learning},
  Mendeley-tags            = {CNN,Decision Forests,Deep Learning},
  Url                      = {http://arxiv.org/abs/1603.01250},
  Volume                   = {58}
}

@InProceedings{Ioannou2016,
  Title                    = {{Training CNNs with Low-Rank Filters for Efficient Image Classification}},
  Author                   = {Ioannou, Yani and Robertson, Duncan P and Shotton, Jamie and Cipolla, Roberto and Criminisi, Antonio},
  Booktitle                = {{International Conference on Learning Representations}},
  Year                     = {2016}
}

@InProceedings{Ioannou2009,
  Title                    = {{Local PotentialWell Space Embedding}},
  Author                   = {Ioannou, Yani and Shang, L},
  Booktitle                = {{{\ldots} Workshops), 2009 IEEE {\ldots}}},
  Year                     = {2009},
  Pages                    = {1726--1732},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioannou - 2009 - Local Potential Well Space Embedding.pdf:pdf},
  ISBN                     = {9781424444410},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5457491}
}

@InProceedings{Ioannou2009a,
  Title                    = {{Local potentialwell space embedding}},
  Author                   = {Ioannou, Y. and Shang, L. and Harrap, R. and Greenspan, M.},
  Booktitle                = {{2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops 2009}},
  Year                     = {2009},
  Pages                    = {1726--1732},

  Abstract                 = {Potential Well Space Embedding (PWSE) has been shown to be an effective global method to recognize segmented objects in range data. Here Local PWSE is proposed as an extension of PWSE. LPWSE features are generated by iterating ICP to the local minima of a multiscale registration model at each point. The locations of the local minima are then used to generate feature vectors, which can be matched against a preprocessed database of such features to determine correspondences between images and models. The method has been implemented and tested on real data, and has been found to be effective at recognizing sparse segmented (self-)occluded range images. A classifi-cation accuracy of 92{\%} is achieved with 3750 points, dropping to 78{\%} at 500 points, on 50 randomly sub-sampled sparse views of 5 objects. {\textcopyright}2009 IEEE.},
  Doi                      = {10.1109/ICCVW.2009.5457491},
  ISBN                     = {9781424444427}
}

@InProceedings{ioannou2009local,
  Title                    = {{Local PotentialWell Space Embedding}},
  Author                   = {Ioannou, Y and Shang, L and Harrap, R and Greenspan, M},
  Booktitle                = {{Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th International Conference on}},
  Year                     = {2009},
  Organization             = {IEEE},
  Pages                    = {1726--1732}
}

@Article{Ioannou2012,
  Title                    = {{Difference of Normals as a Multi-Scale Operator in Unorganized Point Clouds}},
  Author                   = {Ioannou, Yani and Taati, B and Harrap, R and Greenspan, M},
  Journal                  = {3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), 2012 Second International Conference on},
  Year                     = {2012},
  Pages                    = {501--508},

  Abstract                 = {A novel multi-scale operator for unorganized 3D point clouds is introduced. The Difference of Normals (DoN) provides a computationally efficient, multi-scale approach to processing large unorganized 3D point clouds. The application of DoN in the multi-scale filtering of two different real-world outdoor urban LIDAR scene datasets is quantitatively and qualitatively demonstrated. In both datasets the DoN operator is shown to segment large 3D point clouds into scale-salient clusters, such as cars, people, and lamp posts towards applications in semi-automatic annotation, and as a pre-processing step in automatic object recognition. The application of the operator to segmentation is evaluated on a large public dataset of outdoor LIDAR scenes with ground truth annotations.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1209.1759v1},
  Eprint                   = {arXiv:1209.1759v1},
  Keywords                 = {point cloud; lidar; segmentation; multi-scale},
  Mendeley-tags            = {point cloud, lidar, segmentation, multi-scale},
  Url                      = {http://arxiv.org/abs/1209.1759}
}

@Article{ioannou2012difference,
  Title                    = {{Difference of Normals as a Multi-Scale Operator in Unorganized Point Clouds}},
  Author                   = {Ioannou, Y and Taati, B and Harrap, R and Greenspan, M},
  Journal                  = {arXiv preprint arXiv:1209.1759},
  Year                     = {2012},

  File                     = {:home/yani/resume/don3dimpvt.pdf:pdf}
}

@InProceedings{Ioffe2015,
  Title                    = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.}},
  Author                   = {Ioffe, Sergey and Szegedy, Christian},
  Booktitle                = {{Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015}},
  Year                     = {2015}
}

@InProceedings{journals/corr/JaderbergVZ14,
  Title                    = {{Speeding up Convolutional Neural Networks with Low Rank Expansions.}},
  Author                   = {Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
  Booktitle                = {{British Machine Vision Conference}},
  Year                     = {2014},

  Keywords                 = {dblp}
}

@InProceedings{jain2016structural,
  Title                    = {{Structural-RNN: Deep learning on spatio-temporal graphs}},
  Author                   = {Jain, Ashesh and Zamir, Amir R and Savarese, Silvio and Saxena, Ashutosh},
  Booktitle                = {{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2016},
  Pages                    = {5308--5317}
}

@Article{Jhurani2015,
  Title                    = {{A GEMM interface and implementation on NVIDIA GPUs for multiple small matrices}},
  Author                   = {Jhurani, Chetan and Mullowney, Paul},
  Journal                  = {Journal of Parallel and Distributed Computing},
  Year                     = {2015},
  Pages                    = {133--140},
  Volume                   = {75},

  Publisher                = {Elsevier}
}

@Article{Jia2014,
  Title                    = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
  Author                   = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal                  = {ACM International Conference on Multimedia},
  Year                     = {2014},
  Pages                    = {675--678},

  Abstract                 = {Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU ({\$}\backslashapprox{\$} 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1408.5093},
  Doi                      = {10.1145/2647868.2654889},
  Eprint                   = {1408.5093},
  ISBN                     = {9781450330633},
  ISSN                     = {10636919},
  Keywords                 = {computation; computer vision; corresponding authors; machine learning; neural networks; open source; parallel},
  Pmid                     = {18267787},
  Url                      = {http://arxiv.org/abs/1408.5093}
}

@Article{johnson1984extensions,
  Title                    = {{Extensions of Lipschitz mappings into a Hilbert space}},
  Author                   = {Johnson, William B and Lindenstrauss, Joram},
  Journal                  = {Contemporary mathematics},
  Year                     = {1984},
  Pages                    = {189--206},
  Volume                   = {26},

  Abstract                 = {In this note we consider the following extension problem for Lipschitz functions: Given a metric space X and n= 2, 3, 4,, estimate the smallest constant L= L (X, n) so that every mapping f from every n---element subset of X into 62 extends to a mapping I from X into E with 2 ufn, ip 5 L uanp.},
  Doi                      = {10.1090/conm/026/737400},
  ISBN                     = {082185030X 9780821850305},
  ISSN                     = {1042-9832}
}

@InProceedings{kaski1998dimensionality,
  Title                    = {{Dimensionality reduction by random mapping: Fast similarity computation for clustering}},
  Author                   = {Kaski, Samuel},
  Booktitle                = {{Neural Networks Proceedings, 1998. IEEE World Congress on Computational Intelligence. The 1998 IEEE International Joint Conference on}},
  Year                     = {1998},
  Organization             = {IEEE},
  Pages                    = {413--418},
  Volume                   = {1}
}

@Article{Kim2012,
  Title                    = {{A New In-Camera Imaging Model for Color Computer Vision and its Application.}},
  Author                   = {Kim, Seon Joo and Lin, Hai Ting and Lu, Zheng and Susstrunk, Sabine and Lin, Stephen and Brown, Michael S},
  Journal                  = {IEEE transactions on pattern analysis and machine intelligence},
  Year                     = {2012},

  Month                    = {feb},
  Number                   = {X},
  Pages                    = {1--14},
  Volume                   = {X},

  Abstract                 = {We present a study of the in-camera image processing through an extensive analysis of more than 10,000 images from over 30 cameras. The goal of this work is to investigate if image values can be transformed to physically meaningful values, and if so, when and how this can be done. From our analysis, we found a major limitation of the imaging model employed in conventional radiometric calibration methods and propose a new in-camera imaging model that fits well with today's cameras. With the new model, we present associated calibration procedures that allow us to convert an sRGB images back to their original CCD RAW responses in a manner that is significantly more accurate than any existing methods. Additionally, we show how this new imaging model can be used to build an image correction application that converts an sRGB input image captured with the wrong camera settings to an sRGB output image that would have been recorded under the correct settings of a specific camera.},
  Doi                      = {10.1109/TPAMI.2012.58},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2012 - A New In-Camera Imaging Model for Color Computer Vision and its Application.pdf:pdf},
  ISSN                     = {1939-3539},
  Pmid                     = {22371428},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/22371428}
}

@InProceedings{Kim2016,
  Title                    = {{Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications}},
  Author                   = {Kim, Yong-Deok and Park, Eunhyeok and Yoo, Sungjoo and Choi, Taelim and Yang, Lu and Shin, Dongjun},
  Booktitle                = {{International Conference on Learning Representations (ICLR)}},
  Year                     = {2016},
  Pages                    = {1--16},

  Abstract                 = {Although the latest high-end smartphone has powerful CPU and GPU, running deeper convolutional neural networks (CNNs) for complex tasks such as ImageNet classification on mobile devices is challenging. To deploy deep CNNs on mobile devices, we present a simple and effective scheme to compress the entire CNN, which we call one-shot whole network compression. The proposed scheme consists of three steps: (1) rank selection with variational Bayesian matrix factorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning to recover accumulated loss of accuracy, and each step can be easily implemented using publicly available tools. We demonstrate the effectiveness of the proposed scheme by testing the performance of various compressed CNNs (AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant reductions in model size, runtime, and energy consumption are obtained, at the cost of small loss in accuracy. In addition, we address the important implementation level issue on 1?1 convolution, which is a key operation of inception module of GoogLeNet as well as CNNs compressed by our proposed scheme.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1511.06530},
  Eprint                   = {1511.06530},
  Url                      = {http://arxiv.org/abs/1511.06530}
}

@InProceedings{Krizhevsky2014,
  Title                    = {{One weird trick for parallelizing convolutional neural networks}},
  Author                   = {Krizhevsky, Alex},
  Booktitle                = {{arXiv preprint}},
  Year                     = {2014},
  Pages                    = {1--7},

  Abstract                 = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales signiﬁcantly better than all alternatives when applied to modern convolutional neural networks.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1404.5997v2},
  Eprint                   = {arXiv:1404.5997v2},
  Url                      = {http://arxiv.org/abs/1404.5997}
}

@Article{Krizhevsky2014a,
  Title                    = {{One weird trick for parallelizing convolutional neural networks}},
  Author                   = {Krizhevsky, Alex},
  Journal                  = {arXiv preprint},
  Year                     = {2014},
  Pages                    = {1--7},

  Abstract                 = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales signiﬁcantly better than all alternatives when applied to modern convolutional neural networks.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1404.5997v2},
  Eprint                   = {arXiv:1404.5997v2},
  Url                      = {http://arxiv.org/abs/1404.5997}
}

@TechReport{CIFAR10,
  Title                    = {{Learning Multiple Layers of Features from Tiny Images}},
  Author                   = {Krizhevsky, Alex},
  Institution              = {Univ. Toronto},
  Year                     = {2009},
  Type                     = {Technical Report},

  Abstract                 = {Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it difficult to learn a good set of filters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly improved by pre-training a layer of features on a large set of unlabeled tiny images.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1011.1669v3},
  Booktitle                = {{{\ldots} Science Department, University of Toronto, Tech. {\ldots}}},
  Eprint                   = {arXiv:1011.1669v3},
  ISBN                     = {9788578110796},
  ISSN                     = {1098-6596},
  Pages                    = {1--60},
  Pmid                     = {25246403},
  Url                      = {http://scholar.google.com/scholar?hl=en{&}btnG=Search{&}q=intitle:Learning+Multiple+Layers+of+Features+from+Tiny+Images{#}0}
}

@InProceedings{Krizhevsky2012,
  Title                    = {{ImageNet Classification with Deep Convolutional Neural Networks}},
  Author                   = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  Booktitle                = {{Advances In Neural Information Processing Systems}},
  Year                     = {2012},

  Abstract                 = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1102.0183},
  Doi                      = {10.1016/j.protcy.2014.09.007},
  Eprint                   = {1102.0183}
}

@Article{Laptev2005,
  Title                    = {{On Space-Time Interest Points}},
  Author                   = {Laptev, Ivan},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2005},
  Number                   = {2-3},
  Pages                    = {107--123},
  Volume                   = {64},

  Abstract                 = {Local image features or interest points provide compact and abstract representations of patterns in an image. In this paper, we extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for interpretation of spatio-temporal events.},
  Doi                      = {10.1007/s11263-005-1838-7},
  ISSN                     = {09205691},
  Keywords                 = {interest points; matching; scale selection; scale space; video interpretation},
  Publisher                = {Springer},
  Url                      = {http://www.springerlink.com/index/10.1007/s11263-005-1838-7}
}

@Article{larsen2016optimality,
  Title                    = {{Optimality of the Johnson-Lindenstrauss Lemma}},
  Author                   = {Larsen, Kasper Green and Nelson, Jelani},
  Journal                  = {arXiv preprint arXiv:1609.02094},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {1--11},

  Abstract                 = {For any integers {\$}d, n \backslashgeq 2{\$} and {\$}1/({\{}\backslashmin\backslash{\{}n,d\backslash{\}}{\}}){\^{}}{\{}0.4999{\}} {\textless} \backslashvarepsilon{\textless}1{\$}, we show the existence of a set of {\$}n{\$} vectors {\$}X\backslashsubset \backslashmathbb{\{}R{\}}{\^{}}d{\$} such that any embedding {\$}f:X\backslashrightarrow \backslashmathbb{\{}R{\}}{\^{}}m{\$} satisfying {\$}{\$} $\backslash$forall x,y$\backslash$in X,$\backslash$ (1-$\backslash$varepsilon)$\backslash$|x-y$\backslash$|{\_}2{\^{}}2$\backslash$le $\backslash$|f(x)-f(y)$\backslash$|{\_}2{\^{}}2 $\backslash$le (1+$\backslash$varepsilon)$\backslash$|x-y$\backslash$|{\_}2{\^{}}2 {\$}{\$} must have {\$}{\$} m = $\backslash$Omega($\backslash$varepsilon{\^{}}{\{}-2{\}} $\backslash$lg n). {\$}{\$} This lower bound matches the upper bound given by the Johnson-Lindenstrauss lemma [JL84]. Furthermore, our lower bound holds for nearly the full range of {\$}\backslashvarepsilon{\$} of interest, since there is always an isometric embedding into dimension {\$}\backslashmin\backslash{\{}d, n\backslash{\}}{\$} (either the identity map, or projection onto {\$}\backslashmathop{\{}span{\}}(X){\$}). Previously such a lower bound was only known to hold against linear maps {\$}f{\$}, and not for such a wide range of parameters {\$}\backslashvarepsilon, n, d{\$} [LN16]. The best previously known lower bound for general {\$}f{\$} was {\$}m = \backslashOmega(\backslashvarepsilon{\^{}}{\{}-2{\}}\backslashlg n/\backslashlg(1/\backslashvarepsilon)){\$} [Wel74, Alo03], which is suboptimal for any {\$}\backslashvarepsilon = o(1){\$}.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1609.02094},
  Eprint                   = {1609.02094},
  ISBN                     = {0001415123},
  Url                      = {http://arxiv.org/abs/1609.02094}
}

@InCollection{lattimore2013no,
  Title                    = {{No free lunch versus Occam{\rq}s razor in supervised learning}},
  Author                   = {Lattimore, Tor and Hutter, Marcus},
  Booktitle                = {{Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence}},
  Publisher                = {Springer},
  Year                     = {2013},
  Pages                    = {223--235}
}

@InProceedings{Lebedev2015,
  Title                    = {{Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition.}},
  Author                   = {Lebedev, V and Ganin, Y and Rakhuba, M and Oseledets, I and Lempitsky, V},
  Booktitle                = {{International Conference on Learning Representations}},
  Year                     = {2015}
}

@Article{journals/corr/LebedevGROL14,
  Title                    = {{Speeding-Up Convolutional Neural Networks Using Fine-tuned CP-Decomposition}},
  Author                   = {Lebedev, Vadim and Ganin, Yaroslav and Rakhuba1, Maksim and Oseledets, Ivan and Lempitsky, Victor},
  Journal                  = {International Conference on Learning Representations (ICLR)},
  Year                     = {2015},
  Pages                    = {1--10},
  Volume                   = {abs/1412.6},

  Abstract                 = {We propose a simple two-step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discrim-inative fine-tuning. Given a layer, we use non-linear least squares to compute a low-rank CP-decomposition of the 4D convolution kernel tensor into a sum of a small number of rank-one tensors. At the second step, this decomposition is used to replace the original convolutional layer with a sequence of four convolutional layers with small kernels. After such replacement, the entire network is fine-tuned on the training data using standard backpropagation process. We evaluate this approach on two CNNs and show that it yields larger CPU speedups at the cost of lower accuracy drops compared to previous approaches. For the 36-class character classification CNN, our approach obtains a 8.5x CPU speedup of the whole network with only minor accuracy drop (1{\%} from 91{\%} to 90{\%}). For the standard ImageNet architecture (AlexNet), the approach speeds up the second convolution layer by a factor of 4x at the cost of 1{\%} increase of the overall top-5 classification error.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1412.6553v2},
  Eprint                   = {arXiv:1412.6553v2},
  Keywords                 = {dblp}
}

@Misc{Leclerc1991,
  Title                    = {{The direct computation of height from shading}},

  Author                   = {Leclerc, Y G and Bobick, A F},
  Year                     = {1991},

  Abstract                 = {A method for recovering shape from shading that solves directly for the surface height is presented. By using a discrete formulation of the problem, it is possible to achieve good convergence behavior by employing numerical solution techniques more powerful than gradient descent methods derived from variational calculus. Because this method solves directly for height, it avoids the problem of finding an integrable surface maximally consistent with surface orientation. Furthermore, since additional constraints are not needed to make the problem well posed, a smoothness constraint is used only to drive the system towards a good solution; the weight of the smoothness term is eventually reduced to near zero. By solving directly for height, stereo processing may be used to provide initial and boundary conditions. The shape from shading technique, as well as its relation to stereo, is demonstrated on both synthetic and real imagery},
  Booktitle                = {{Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}},
  Doi                      = {10.1109/CVPR.1991.139752},
  ISBN                     = {0818621486},
  ISSN                     = {10636919},
  Pages                    = {552--558},
  Publisher                = {IEEE Comput. Sco. Press},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=139752},
  Volume                   = {91}
}

@Article{Lecun2015,
  Title                    = {{Deep learning}},
  Author                   = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  Journal                  = {Nature},
  Year                     = {2015},
  Number                   = {1},
  Pages                    = {436--444},
  Volume                   = {521},

  Abstract                 = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech rec- ognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1312.6184v5},
  Doi                      = {10.1038/nature14539},
  Eprint                   = {arXiv:1312.6184v5},
  ISBN                     = {9780521835688},
  ISSN                     = {1548-7091},
  Pmid                     = {10463930},
  Url                      = {http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html}
}

@Article{lecun1989backpropagation,
  Title                    = {{Backpropagation applied to handwritten zip code recognition}},
  Author                   = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  Journal                  = {Neural computation},
  Year                     = {1989},
  Number                   = {4},
  Pages                    = {541--551},
  Volume                   = {1},

  Publisher                = {MIT Press}
}

@Article{Lecun1998,
  Title                    = {{Gradient-based learning applied to document recognition}},
  Author                   = {Lecun, Y and Bottou, L and Bengio, Y and Haffner, P},
  Journal                  = {Proceedings of the IEEE},
  Year                     = {1998},
  Number                   = {11},
  Pages                    = {2278--2324},
  Volume                   = {86},

  Abstract                 = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
  ISSN                     = {0018-9219},
  Keywords                 = {2D GTN; back-propagation; backpropagation; based c}
}

@Article{lecun1989generalization,
  Title                    = {{Generalization and network design strategies}},
  Author                   = {LeCun, Yann and others},
  Journal                  = {Connectionism in perspective},
  Year                     = {1989},
  Pages                    = {143--155},

  Publisher                = {Zurich, Switzerland: Elsevier}
}

@Article{Lee2005,
  Title                    = {{Mesh saliency}},
  Author                   = {Lee, Chang Ha and Varshney, Amitabh and Jacobs, David W},
  Journal                  = {ACM Transactions on Graphics},
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {659},
  Volume                   = {24},

  Abstract                 = {Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. In this paper we introduce the idea of mesh saliency as a measure of regional importance for graphics meshes. Our notion of saliency is inspired by low-level human visual system cues. We define mesh saliency in a scale-dependent manner using a center-surround operator on Gaussian-weighted mean curvatures. We observe that such a definition of mesh saliency is able to capture what most would classify as visually interesting regions on a mesh. The human-perception-inspired importance measure computed by our mesh saliency operator results in more visually pleasing results in processing and viewing of 3D meshes. compared to using a purely geometric measure of shape. such as curvature. We discuss how mesh saliency can be incorporated in graphics applications such as mesh simplification and viewpoint selection and present examples that show visually appealing results from using mesh saliency.},
  Doi                      = {10.1145/1073204.1073244},
  ISSN                     = {07300301},
  Keywords                 = {perception; saliency; simplification; visual attention},
  Publisher                = {ACM},
  Series                   = {{SIGGRAPH '05}},
  Url                      = {http://portal.acm.org/citation.cfm?doid=1073204.1073244}
}

@Article{lee2014deeply,
  Title                    = {{Deeply-Supervised Nets}},
  Author                   = {Lee, Chen-Yu and Xie, Saining and Gallagher, Patrick and Zhang, Zhengyou and Tu, Zhuowen},
  Journal                  = {arXiv preprint arXiv:1409.5185},
  Year                     = {2014},

  Abstract                 = {Our proposed deeply-supervised nets (DSN) method simultaneously minimizes classification error while making the learning process of hidden layers direct and transparent. We make an attempt to boost the classification performance by studying a new formulation in deep networks. Three aspects in convolutional neural networks (CNN) style architectures are being looked at: (1) transparency of the intermediate layers to the overall classification; (2) discriminativeness and robustness of learned features, especially in the early layers; (3) effectiveness in training due to the presence of the exploding and vanishing gradients. We introduce "companion objective" to the individual hidden layers, in addition to the overall objective at the output layer (a different strategy to layer-wise pre-training). We extend techniques from stochastic gradient methods to analyze our algorithm. The advantage of our method is evident and our experimental result on benchmark datasets shows significant performance gain over existing methods (e.g. all state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and SVHN).},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1409.5185},
  Eprint                   = {1409.5185},
  ISSN                     = {15337928},
  Url                      = {http://arxiv.org/abs/1409.5185}
}

@TechReport{Leichter2012,
  Title                    = {{Monotonicity and Error Type Diﬀerentiability in Performance Measures for Target Detection and Tracking in Video}},
  Author                   = {Leichter, Ido and Krupka, Eyal},
  Institution              = {Advanced Technology Labs Israel, Microsoft Research},
  Year                     = {2012},

  Url                      = {http://research.microsoft.com/pubs/160662/MSR-TR-2012-23updated.pdf}
}

@Article{Levin2007,
  Title                    = {{Image and depth from a conventional camera with a coded aperture}},
  Author                   = {Levin, Anat and Fergus, Rob and Durand, Fr{\'e}do and Freeman, William T},
  Journal                  = {ACM Transactions on Graphics},
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {70},
  Volume                   = {26},

  Abstract                 = {Individuals susceptible to high-altitude pulmonary oedema (HAPE) are characterised by an abnormal increase of pulmonary artery systolic pressure (PASP) in hypoxia and during normoxic exercise, reduced hypoxic ventilatory response, and smaller lung volume. In 37 mountaineers with well-documented altitude tolerance, it was investigated whether any combination of these noninvasive measurements, including exercise in hypoxia, could improve the identification of HAPE-susceptible subjects at low altitude. HAPE-susceptible subjects showed a significant higher increase of PASP during hypoxia at rest (48+/-10 mmHg) compared with controls (38+/-3 mmHg), as well as during normoxic exercise (57+/-14 versus 38+/-7 mmHg) and hypoxic exercise (69+/-13 versus 49+/-8 mmHg). PASP could not be assessed in three and eight subjects during normoxic or hypoxic exercise, respectively, due to insufficient Doppler profiles or systemic arterial hypertension. Sensitivity (77-94{\%}) and specificity (76-93{\%}) were not significantly different between the various testing conditions. Additional assessment of hypoxic ventilatory response and lung function parameters did not improve identification of HAPE-susceptible subjects in a multivariate analysis. Due to the greater number of missing values in pulmonary artery systolic pressure measurements during hypoxic exercise, it was concluded that pulmonary artery systolic pressure measurements at rest during hypoxia or exercise in normoxia are most feasible for the identification of high-altitude pulmonary oedema-susceptible subjects.},
  Doi                      = {10.1145/1276377.1276464},
  Institution              = {ACM},
  ISBN                     = {9781595936486},
  ISSN                     = {07300301},
  Keywords                 = {coded imaging; computational photography; deblurring; depth; field; image statistics; range estimation},
  Pmid                     = {15738301},
  Publisher                = {ACM},
  Url                      = {http://portal.acm.org/citation.cfm?doid=1276377.1276464}
}

@Article{Levoy2000,
  Title                    = {{The digital Michelangelo project: 3D scanning of large statues}},
  Author                   = {Levoy, Marc and Pulli, Kari and Curless, Brian},
  Journal                  = {Proceedings of the 27th {\ldots}},
  Year                     = {2000},
  Pages                    = {131--144},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levoy, Pulli, Curless - 2000 - The digital Michelangelo project 3D scanning of large statues.pdf:pdf},
  ISBN                     = {1581132085},
  Url                      = {http://dl.acm.org/citation.cfm?id=344849}
}

@Article{Lin2011,
  Title                    = {{Revisiting radiometric calibration for color computer vision}},
  Author                   = {Lin, Haiting and Susstrunk, Sabine and Brown, Michael S.},
  Journal                  = {2011 International Conference on Computer Vision},
  Year                     = {2011},

  Month                    = {nov},
  Pages                    = {129--136},

  Doi                      = {10.1109/ICCV.2011.6126234},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Susstrunk, Brown - 2011 - Revisiting radiometric calibration for color computer vision.pdf:pdf},
  ISBN                     = {978-1-4577-1102-2},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126234}
}

@InProceedings{Lin2014,
  Title                    = {{Network in network}},
  Author                   = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  Booktitle                = {{International Conference on Learning Representations (ICLR)}},
  Year                     = {2014},
  Series                   = {{2014}}
}

@Article{Lin2013NiN,
  Title                    = {{Network In Network}},
  Author                   = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  Journal                  = {arXiv preprint},
  Year                     = {2013},
  Pages                    = {10},
  Volume                   = {abs/1312.4},

  Abstract                 = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1312.4400},
  Doi                      = {10.1109/ASRU.2015.7404828},
  Eprint                   = {1312.4400},
  ISBN                     = {9781479972913},
  Keywords                 = {In Network},
  Url                      = {http://arxiv.org/abs/1312.4400}
}

@InProceedings{Lin2014a,
  Title                    = {{Microsoft COCO: Common objects in context}},
  Author                   = {Lin, Tsung Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence},
  Booktitle                = {{Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}},
  Year                     = {2014},
  Number                   = {PART 5},
  Pages                    = {740--755},
  Volume                   = {8693 LNCS},

  Abstract                 = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1405.0312v1},
  Doi                      = {10.1007/978-3-319-10602-1_48},
  Eprint                   = {arXiv:1405.0312v1},
  ISBN                     = {978-3-319-10601-4},
  ISSN                     = {16113349}
}

@Article{Lowe2004,
  Title                    = {{Distinctive Image Features from Scale-Invariant Keypoints}},
  Author                   = {Lowe, David G},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {91--110},
  Volume                   = {60},

  Abstract                 = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  Doi                      = {10.1023/B:VISI.0000029664.99615.94},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Keypoints.pdf:pdf},
  ISBN                     = {1568811012},
  ISSN                     = {09205691},
  Pmid                     = {20064111},
  Publisher                = {Springer},
  Series                   = {{Int. J. Comput. Vis. (Netherlands)}},
  Url                      = {http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000029664.99615.94}
}

@InProceedings{Luo2010switchable,
  Title                    = {{Switchable Deep Networks for Pedestrian Detection}},
  Author                   = {Luo, P and Tian, Y and Wang, X and Tang, X},
  Booktitle                = {{Proceedings of the 2010 IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2010}
}

@Article{mackay1992practical,
  Title                    = {{A practical Bayesian framework for backpropagation networks}},
  Author                   = {MacKay, David JC},
  Journal                  = {Neural computation},
  Year                     = {1992},
  Number                   = {3},
  Pages                    = {448--472},
  Volume                   = {4}
}

@PhdThesis{MacKay91,
  Title                    = {{Bayesian Methods for Adaptive Models}},
  Author                   = {MacKay, D. J. C.},
  School                   = {California Institute of Technology},
  Year                     = {1991}
}

@InCollection{mamalet2012simplifying,
  Title                    = {{Simplifying convnets for fast learning}},
  Author                   = {Mamalet, Franck and Garcia, Christophe},
  Booktitle                = {{Artificial Neural Networks and Machine Learning--ICANN 2012}},
  Publisher                = {Springer},
  Year                     = {2012},
  Pages                    = {58--65}
}

@Article{Martinez-Verdu1998,
  Title                    = {{Spectroradiometric characterization of the spectral linearity of a conventional digital camera}},
  Author                   = {Mart{\'i}nez-Verd{\'u}, Francisco Miguel and Pujol, Jaume and Bouzada, Alejandro and Capilla, Pascual},
  Journal                  = {Proceedings of the SPIE},
  Year                     = {1998},
  Number                   = {January 1999},
  Pages                    = {279--290},
  Volume                   = {3648},

  Doi                      = {10.1117/12.334567},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mart{\'i}nez-Verd{\'u} et al. - 1998 - Spectroradiometric characterization of the spectral linearity of a conventional digital camera.pdf:pdf},
  Keywords                 = {colorimetry; digital cameras; image input device characterisation; spectral sensitivity},
  Publisher                = {SPIE},
  Url                      = {http://link.aip.org/link/?PSI/3648/279/1{&}Agg=doi}
}

@InProceedings{martens2010deep,
  Title                    = {{Deep learning via Hessian-free optimization}},
  Author                   = {Martens, James},
  Booktitle                = {{Proceedings of the 27th International Conference on Machine Learning (ICML-10)}},
  Year                     = {2010},
  Pages                    = {735--742}
}

@Article{mathieu2013fast,
  Title                    = {{Fast Training of Convolutional Networks through FFTs}},
  Author                   = {Mathieu, Michael and Henaff, Mikael and LeCun, Y},
  Journal                  = {International Conference on Learning Representations (ICLR)},
  Year                     = {2014},
  Pages                    = {1--9},

  Abstract                 = {Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a signiﬁcant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {arXiv:1312.5851v5},
  Eprint                   = {arXiv:1312.5851v5},
  Url                      = {http://arxiv.org/abs/1312.5851}
}

@InProceedings{Mathieu2014,
  Title                    = {{Fast training of convolutional networks through {\{}FFTs{\}}}},
  Author                   = {Mathieu, Michael and Henaff, Mikael and LeCun, Yann},
  Booktitle                = {{International Conference on Learning Representations (ICLR)}},
  Year                     = {2014}
}

@Article{mezard1989learning,
  Title                    = {{Learning in feedforward layered networks: The tiling algorithm}},
  Author                   = {Mezard, Marc and Nadal, Jean-P},
  Journal                  = {Journal of Physics A: Mathematical and General},
  Year                     = {1989},
  Number                   = {12},
  Pages                    = {2191},
  Volume                   = {22},

  Publisher                = {IOP Publishing}
}

@Book{minsky1988perceptrons,
  Title                    = {{Perceptrons}},
  Author                   = {Minsky, Marvin and Papert, Seymour},
  Publisher                = {MIT press},
  Year                     = {1988}
}

@Article{Mitsunaga1999,
  Title                    = {{Radiometric self calibration}},
  Author                   = {Mitsunaga, T. and Nayar, S.K.},
  Journal                  = {Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
  Year                     = {1999},
  Pages                    = {374--380},

  Doi                      = {10.1109/CVPR.1999.786966},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitsunaga, Nayar - 1999 - Radiometric self calibration.pdf:pdf},
  ISBN                     = {0-7695-0149-4},
  Publisher                = {IEEE Comput. Soc},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=786966}
}

@Article{Mohr1996,
  Title                    = {{Projective Geometry for Image Analysis}},
  Author                   = {Mohr, Roger and Triggs, Bill},
  Journal                  = {Int Symp Photogrammetry and Remote Sensing},
  Year                     = {1996},
  Number                   = {July},

  Abstract                 = {Significant progress has recently been made by applying tools fromclassical projective and algebraic geometry to fundamental problems in computer vision. To some extent this work was foreshadowed by early mathematical photogrammetrists. However the modern approach has gone far beyond these early studies, particularly as regards our ability to deal with multiple images and unknown camera parameters, and on practical computational issues such as stability, robustness and precision. These new techniques are greatly extending the scope and flexibility of digital photogrammetric systems. This tutorial provides a practical, applications-oriented introduction to the projective geometry needed to understand these new developments. No currently available textbook covers all of this material, although several existing texts consider parts of it. Kanatanis book 11 studies many computational and statistical aspects of computer vision in a projective framework. Faugeras 4 investigates the geometric aspects of 3D vision, including several of the projective results obtained by his team before 1993. The collections edited by Mundy, Zisserman and Forsyth 18, 19 summarize recent research on the applications of geometric invariants to computer vision: projective results are central to this programme. Mathematical introductions to projective geometry can be found in many books. A standard text covering the necessary aspects of both projective and algebraic geometry is Semple and Kneebone 23. Unfortunately this is currently out of print, however many scientific libraries have it and it is said to be reprinting soon.},
  Institution              = {ISPRS workshop tutorial},
  Publisher                = {Citeseer},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.3924{&}rep=rep1{&}type=pdf}
}

@InProceedings{montillo2011entangled,
  Title                    = {{Entangled decision forests and their application for semantic segmentation of CT images}},
  Author                   = {Montillo, Albert and Shotton, Jamie and Winn, John and Iglesias, Juan Eugenio and Metaxas, Dimitri and Criminisi, Antonio},
  Booktitle                = {{Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}},
  Year                     = {2011},
  Pages                    = {184--196},
  Volume                   = {6801 LNCS},

  Abstract                 = {This work addresses the challenging problem of simultaneously segmenting multiple anatomical structures in highly varied CT scans. We propose the entangled decision forest (EDF) as a new discriminative classifier which augments the state of the art decision forest, resulting in higher prediction accuracy and shortened decision time. Our main contribution is two-fold. First, we propose entangling the binary tests applied at each tree node in the forest, such that the test result can depend on the result of tests applied earlier in the same tree and at image points offset from the voxel to be classified. This is demonstrated to improve accuracy and capture long-range semantic context. Second, during training, we propose injecting randomness in a guided way, in which node feature types and parameters are randomly drawn from a learned (nonuniform) distribution. This further improves classification accuracy. We assess our probabilistic anatomy segmentation technique using a labeled database of CT image volumes of 250 different patients from various scan protocols and scanner vendors. In each volume, 12 anatomical structures have been manually segmented. The database comprises highly varied body shapes and sizes, a wide array of pathologies, scan resolutions, and diverse contrast agents. Quantitative comparisons with state of the art algorithms demonstrate both superior test accuracy and computational efficiency.},
  Doi                      = {10.1007/978-3-642-22092-0_16},
  ISBN                     = {9783642220913},
  ISSN                     = {03029743},
  Keywords                 = {CT; Entanglement; auto-context; decision forests; segmentation},
  Pmid                     = {21761656}
}

@InProceedings{mozer1989skeletonization,
  Title                    = {Skeletonization: A technique for trimming the fat from a network via relevance assessment},
  Author                   = {Mozer, Michael C and Smolensky, Paul},
  Booktitle                = {Advances in neural information processing systems},
  Year                     = {1989},
  Pages                    = {107--115},

  Owner                    = {yani},
  Timestamp                = {2017.09.13}
}

@Article{mozer1989using,
  Title                    = {Using relevance to reduce network size automatically},
  Author                   = {Mozer, Michael C and Smolensky, Paul},
  Journal                  = {Connection Science},
  Year                     = {1989},
  Number                   = {1},
  Pages                    = {3--16},
  Volume                   = {1},

  Owner                    = {yani},
  Publisher                = {Taylor \& Francis},
  Timestamp                = {2017.09.13}
}

@InProceedings{conf/icml/NairH10,
  Title                    = {{Rectified Linear Units Improve Restricted Boltzmann Machines}},
  Author                   = {Nair, Vinod and Hinton, Geoffrey E},
  Booktitle                = {{Proceedings of the 27th International Conference on Machine Learning}},
  Year                     = {2010},
  Editor                   = {F{\"u}rnkranz, Johannes and Joachims, Thorsten},
  Number                   = {3},
  Pages                    = {807--814},
  Publisher                = {Omnipress},

  Abstract                 = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these ``Stepped Sigmoid Units'' are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
  ISBN                     = {9781605589077},
  ISSN                     = {1935-8237},
  Keywords                 = {dblp},
  Pmid                     = {22404682},
  Url                      = {http://dblp.uni-trier.de/db/conf/icml/icml2010.html{\#}NairH10}
}

@Article{Narayana2012,
  Title                    = {{Background Modeling Using Adaptive Pixelwise Kernel Variances in a Hybrid Feature Space}},
  Author                   = {Narayana, Manjunath and Hanson, Allen and Learned-miller, Erik},
  Journal                  = {viswwwcsumassedu},
  Year                     = {2012},

  Url                      = {http://vis-www.cs.umass.edu/papers/Manjunath{\_}background{_}CVPR2012.pdf}
}

@Article{Ng2006,
  Title                    = {{Digital light field photography}},
  Author                   = {Ng, R},
  Year                     = {2006},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng - 2006 - Digital light field photography.pdf:pdf},
  Url                      = {http://testcis.cis.rit.edu/{~}cnspci/references/dip/light{_}field{_}photography/ng2006.pdf}
}

@Misc{Numagami1995,
  Title                    = {{Reconstruction of the 3-D shape of an object from a 2-D intensity image}},

  Author                   = {Numagami, Y and Kajiwara, Y and Nakamura, O and Minami, T},
  Year                     = {1995},

  Abstract                 = {In this paper, a reconstruction method of a curved object from a single gray-level image is proposed. To realize easy but robust shape from shading (SFS), the proposed method adopts isodensity lines. The results of computer simulation using virtual objects show that the prospects of using this method are very encouraging},
  Booktitle                = {{Proceedings 1995 Canadian Conference on Electrical and Computer Engineering}},
  Doi                      = {10.1109/CCECE.1995.526675},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Numagami et al. - 1995 - Reconstruction of the 3-D shape of an object from a 2-D intensity image.pdf:pdf},
  ISBN                     = {0780327667},
  ISSN                     = {08407789},
  Volume                   = {2}
}

@InProceedings{Oquab:2014:LTM:2679600.2680210,
  Title                    = {{Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks}},
  Author                   = {Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  Booktitle                = {{Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2014},

  Address                  = {Washington, DC, USA},
  Pages                    = {1717--1724},
  Publisher                = {IEEE Computer Society},
  Series                   = {{CVPR '14}},

  Doi                      = {10.1109/CVPR.2014.222},
  ISBN                     = {978-1-4799-5118-5},
  Url                      = {http://dx.doi.org/10.1109/CVPR.2014.222}
}

@Article{Ortiz2004,
  Title                    = {{Radiometric calibration of CCD sensors: Dark current and fixed pattern noise estimation}},
  Author                   = {Ortiz, Albert and Oliver, Gabriel},
  Journal                  = {{\ldots} , 2004. Proceedings. ICRA'04. 2004 IEEE {\ldots}},
  Year                     = {2004},
  Number                   = {April},
  Pages                    = {4730--4735},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ortiz, Oliver - 2004 - Radiometric calibration of CCD sensors Dark current and fixed pattern noise estimation.pdf:pdf},
  ISBN                     = {0780382323},
  Keywords                 = {- robot vision; camera calibration; sensors},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1302465}
}

@Book{Palmer2009,
  Title                    = {{The Art of Radiometry}},
  Author                   = {Palmer, James M and Grant, Barbara G},
  Publisher                = {SPIE Press},
  Year                     = {2009},
  Series                   = {{Press Monograph}},
  Volume                   = {PM184},

  Booktitle                = {{SPIE Press Monograph}},
  Doi                      = {10.1117/3.798237},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry.pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(2).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(3).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(4).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(5).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(6).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(7).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(8).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(9).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(10).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(11).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(12).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(13).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(14).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(15).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(16).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(17).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(18).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(19).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(20).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(21).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(22).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(23).pdf:pdf;:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palmer, Grant - 2009 - The Art of Radiometry(24).pdf:pdf},
  ISBN                     = {9780819472458},
  Pages                    = {384},
  Url                      = {http://books.google.com/books?id=WCwBQgAACAAJ}
}

@Article{parekh2000constructive,
  Title                    = {{Constructive neural-network learning algorithms for pattern classification}},
  Author                   = {Parekh, Rajesh and Yang, Jihoon and Honavar, Vasant},
  Journal                  = {IEEE Transactions on neural networks},
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {436--451},
  Volume                   = {11},

  Publisher                = {IEEE}
}

@Misc{Park2011,
  Title                    = {{3D reconstruction of a smooth articulated trajectory from a monocular image sequence}},

  Author                   = {Park, Hyun Soo and Sheikh, Yaser},
  Year                     = {2011},

  Abstract                 = {An articulated trajectory is defined as a trajectory that remains at a fixed distance with respect to a parent trajectory. In this paper, we present a method to reconstruct an articulated trajectory in three dimensions given the two dimensional projection of the articulated trajectory, the 3D parent trajectory, and the camera pose at each time instant. This is a core challenge in reconstructing the 3D motion of articulated structures such as the human body because endpoints of each limb form articulated trajectories. We simultaneously apply activity-independent spatial and temporal constraints, in the form of fixed 3D distance to the parent trajectory and smooth 3D motion. There exist two solutions that satisfy each instantaneous 2D projection and articulation constraint (a ray intersects a sphere at up to two locations) and we show that resolving this ambiguity by enforcing smoothness is equivalent to solving a binary quadratic programming problem. A geometric analysis of the reconstruction of articulated trajectories is also presented and a measure of the reconstructibility of an articulated trajectory is proposed.},
  Booktitle                = {{2011 International Conference on Computer Vision}},
  Doi                      = {10.1109/ICCV.2011.6126243},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Sheikh - 2011 - 3D reconstruction of a smooth articulated trajectory from a monocular image sequence.pdf:pdf},
  Institution              = {Carnegie Mellon University, 5000 Forbes Ave., Pittsburgh, PA, 15213, USA},
  ISBN                     = {9781457711008},
  ISSN                     = {15505499},
  Pages                    = {201--208},
  Publisher                = {IEEE},
  Url                      = {http://www.andrew.cmu.edu/user/hyunsoop/iccv2011/iccv{\_}project{_}page.html}
}

@Article{Perwass2010,
  Title                    = {{Single Lens 3D-Camera with Extended Depth-of-Field}},
  Author                   = {Perwa{\ss}, Christian and Wietzke, Lennart and Gmbh, Raytrix},
  Year                     = {2010},
  Number                   = {431},
  Volume                   = {49},

  Keywords                 = {3d estimation; extended depth-of-field; plenoptic camera}
}

@Article{polyak1964some,
  Title                    = {Some methods of speeding up the convergence of iteration methods},
  Author                   = {Polyak, Boris T},
  Journal                  = {USSR Computational Mathematics and Mathematical Physics},
  Year                     = {1964},
  Number                   = {5},
  Pages                    = {1--17},
  Volume                   = {4},

  Publisher                = {Elsevier}
}

@Misc{Prados2005,
  Title                    = {{Shape from shading: a well-posed problem?}},

  Author                   = {Prados, E and Faugeras, O},
  Year                     = {2005},

  Abstract                 = {Shape from shading is known to be an ill-posed problem. We show in this paper that if we model the problem in a different way than it is usually done, more precisely by taking into account the 1/r2 attenuation term of the illumination, shape from shading becomes completely well-posed. Thus the shading allows to recover (almost) any surface from only one image (of this surface) without any additional data (in particular, without the knowledge of the heights of the solution at the local intensity "minima", contrary to P. Dupuis et al. (1994), E. Prados et al. (2004), B. Horn (1986), E. Rouy et al. (1992), R. Kimmel et al. (2001)) and without regularity assumptions (contrary to J. Oliensis et al. (1993), R. Kimmel et al. (1995), for example). More precisely, we formulate the problem as that of solving a new partial differential equation (PDE), we develop a complete mathematical study of this equation and we design a new provably convergent numerical method. Finally, we present results of our new shape from shading method on various synthetic and real images.},
  Booktitle                = {{2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR05}},
  Doi                      = {10.1109/CVPR.2005.319},
  ISBN                     = {0769523722},
  ISSN                     = {10636919},
  Number                   = {c},
  Pages                    = {870--877},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467534},
  Volume                   = {2}
}

@Article{Prati2003,
  Title                    = {{Detecting Moving Shadows : Algorithms and Evaluation {\ae}}},
  Author                   = {Prati, Andrea and Mikic, Ivana and Trivedi, Mohan M and Cucchiara, Rita},
  Year                     = {2003},
  Number                   = {7},
  Pages                    = {918--923},
  Volume                   = {25},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prati et al. - 2003 - Detecting Moving Shadows Algorithms and Evaluation {\ae}.pdf:pdf}
}

@Article{Ramamoorthi2001,
  Title                    = {{A signal-processing framework for inverse rendering}},
  Author                   = {Ramamoorthi, Ravi and Hanrahan, Pat},
  Journal                  = {{\ldots} of the 28th annual conference on {\ldots}},
  Year                     = {2001},
  Number                   = {August},
  Pages                    = {12--17},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramamoorthi, Hanrahan - 2001 - A signal-processing framework for inverse rendering.pdf:pdf},
  ISBN                     = {158113374X},
  Keywords                 = {brdf; illumination; inverse; irradiance; light field; radiance; rendering; signal processing; spherical harmonics},
  Url                      = {http://dl.acm.org/citation.cfm?id=383271}
}

@Article{ren2015noc,
  Title                    = {{Object Detection Networks on Convolutional Feature Maps}},
  Author                   = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Zhang, Xiangyu and Sun, Jian},
  Journal                  = {arXiv preprint arXiv:1504.06066},
  Year                     = {2015}
}

@InProceedings{conf/cvpr/RigamontiSLF13,
  Title                    = {{Learning Separable Filters.}},
  Author                   = {Rigamonti, Roberto and Sironi, Amos and Lepetit, Vincent and Fua, Pascal},
  Booktitle                = {{Computer Vision and Pattern Recognition (CVPR)}},
  Year                     = {2013},
  Pages                    = {2754--2761},
  Publisher                = {IEEE},

  Keywords                 = {dblp}
}

@InProceedings{Rippel2015,
  Title                    = {{Spectral Representations for Convolutional Neural Networks}},
  Author                   = {Rippel, Oren and Snoek, Jasper and Adams, Ryan P},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2015},
  Pages                    = {2440--2448}
}

@Article{rippel2015spectral,
  Title                    = {{Spectral Representations for Convolutional Neural Networks}},
  Author                   = {Rippel, Oren and Snoek, Jasper and Adams, Ryan P},
  Journal                  = {Advances in Neural Information Processing Systems 28},
  Year                     = {2015},
  Pages                    = {2440--2448},

  Abstract                 = {Discrete Fourier transforms provide a significant speedup in the computation of convolutions in deep learning. In this work, we demonstrate that, beyond its ad- vantages for efficient computation, the spectral domain also provides a powerful representation in which to model and train convolutional neural networks (CNNs). We employ spectral representations to introduce a number of innovations to CNN design. First, we propose spectral pooling, which performs dimensionality re- duction by truncating the representation in the frequency domain. This approach preserves considerably more information per parameter than other pooling strate- gies and enables flexibility in the choice of pooling output dimensionality. This representation also enables a new form of stochastic regularization by random- ized modification of resolution. We show that these methods achieve competitive results on classification and approximation tasks, without using any dropout or max-pooling. Finally, we demonstrate the effectiveness of complex-coefficient spectral param- eterization of convolutional filters. While this leaves the underlying model un- changed, it results in a representation that greatly facilitates optimization. We observe on a variety of popular CNN configurations that this leads to significantly faster convergence during training. 1},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1506.03767},
  Eprint                   = {1506.03767},
  ISSN                     = {10495258},
  Url                      = {http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf}
}

@TechReport{rosenblatt1961principles,
  Title                    = {{Principles of neurodynamics. perceptrons and the theory of brain mechanisms}},
  Author                   = {Rosenblatt, Frank},
  Institution              = {CORNELL AERONAUTICAL LAB INC BUFFALO NY},
  Year                     = {1961}
}

@Article{rosenblatt1958perceptron,
  Title                    = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  Author                   = {Rosenblatt, Frank},
  Journal                  = {Psychological review},
  Year                     = {1958},
  Number                   = {6},
  Pages                    = {386},
  Volume                   = {65},

  Publisher                = {American Psychological Association}
}

@InProceedings{BuloKontsch2014,
  Title                    = {{Neural Decision Forests for Semantic Image Labelling}},
  Author                   = {{Rota Bul{\`o}}, S and Kontschieder, P},
  Booktitle                = {{Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2014},
  Month                    = jun
}

@Article{rumelhartbackprop,
  Title                    = {{Learning representations by back-propagating errors}},
  Author                   = {{Rumelhart David E.} and {Hinton Geoffrey E.} and {Williams Ronald J.}},
  Journal                  = {Nature},
  Year                     = {1986},

  Month                    = oct,
  Note                     = {10.1038/323533a0},
  Number                   = {6088},
  Pages                    = {533--536},
  Volume                   = {323},

  Doi                      = {10.1038/323533a0},
  Risfield_0_m3            = {10.1038/323533a0}
}

@Article{ILSVRC2015,
  Title                    = {{ImageNet Large Scale Visual Recognition Challenge}},
  Author                   = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C and Fei-Fei, Li},
  Journal                  = {International Journal of Computer Vision (IJCV)},
  Year                     = {2015},

  Doi                      = {10.1007/s11263-015-0816-y}
}

@Article{Rusu2008,
  Title                    = {{Persistent point feature histograms for 3D point clouds}},
  Author                   = {Rusu, RB and Marton, ZC and Blodow, N},
  Journal                  = {autonomous systems 10:},
  Year                     = {2008},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unnikrishnan - 2008 - Statistical approaches to multi-scale point cloud processing.pdf:pdf},
  Keywords                 = {geometric reasoning; persistent feature histograms; point clouds},
  Url                      = {http://books.google.com/books?hl=en{&}lr={&}id=KcYWTosXoOgC{&}oi=fnd{&}pg=PR8{&}dq=Statistical+Approaches+to+Multi-scale+Point+Cloud+Processing{&}ots=A2KI1JjP0A{&}sig=W1BJPYQSqpAT4{_}v2NxUt8G3CoLo http://books.google.com/books?hl=en{&}lr={&}id=KcYWTosXoOgC{&}oi=fnd{&}pg=PR8{&}dq=Statistical+approaches+to+multi-scale+point+cloud+processing{&}ots=A2KI1KiWUB{&}sig=3sFvxrJzE1coUvp9UmQ53IZyIeA http://books.google.com/books?hl=en{&}lr={&}id=0CgdTrB1AEIC{&}oi=fnd{&}pg=}
}

@PhdThesis{Saligrama2012,
  Title                    = {{Video Anomaly Detection Based on Local Statistical Aggregates}},
  Author                   = {Saligrama, Venkatesh and Chen, Zhu},
  Year                     = {2012},

  Booktitle                = {{IEEE Conference on Computer Vision and Pattern Recognition}},
  Url                      = {http://blogs.bu.edu/srv/files/2012/04/cvpr{\_}final.pdf}
}

@Article{schwartz1990exhaustive,
  Title                    = {Exhaustive learning},
  Author                   = {Schwartz, Daniel B and Samalam, Vijay K and Solla, Sara A and Denker, John S},
  Journal                  = {Neural Computation},
  Year                     = {1990},
  Number                   = {3},
  Pages                    = {374--385},
  Volume                   = {2},

  Owner                    = {yani},
  Publisher                = {MIT Press},
  Timestamp                = {2017.09.13}
}

@Article{Sentenac2003,
  Title                    = {{Temperature correction of radiometric and geometric models for an uncooled CCD camera in the near infrared}},
  Author                   = {Sentenac, Thierry},
  Journal                  = {{\ldots} , IEEE Transactions on},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {46--60},
  Volume                   = {52},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sentenac - 2003 - Temperature correction of radiometric and geometric models for an uncooled CCD camera in the near infrared.pdf:pdf},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1191409}
}

@InProceedings{Sermanet2013overfeat,
  Title                    = {{OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks}},
  Author                   = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
  Booktitle                = {{arXiv preprint arXiv}},
  Year                     = {2013},
  Pages                    = {1312.6229},

  Abstract                 = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1312.6229},
  Eprint                   = {1312.6229},
  Url                      = {http://arxiv.org/abs/1312.6229}
}

@TechReport{Sethi1990,
  Title                    = {{Entropy Nets: From Decison Trees to Neural Networks}},
  Author                   = {Sethi, I K},
  Institution              = {Dept. of Computer Sci, Wayne State Univ.},
  Year                     = {1990},
  Number                   = {10},

  Booktitle                = {{Proceedings of the {\{}IEEE{\}}}},
  Pages                    = {1605--1613},
  Volume                   = {78}
}

@Article{setiono1997penalty,
  Title                    = {A penalty-function approach for pruning feedforward neural networks},
  Author                   = {Setiono, Rudy},
  Journal                  = {Neural computation},
  Year                     = {1997},
  Number                   = {1},
  Pages                    = {185--204},
  Volume                   = {9},

  Owner                    = {yani},
  Publisher                = {MIT Press},
  Timestamp                = {2017.09.13}
}

@InProceedings{Shankar2016,
  Title                    = {{Refining Architectures of Deep Convolutional Neural Networks}},
  Author                   = {Shankar, Sukrit and Robertson, Duncan and Ioannou, Yani and Criminisi, Antonio and Cipolla, Roberto},
  Booktitle                = {{Conference on Computer Vision and Pattern Recognition (CVPR), 2016}},
  Year                     = {2016},

  Address                  = {Las Vegas, Nevada, USA},
  Month                    = {jun},

  Abstract                 = {Deep Convolutional Neural Networks (CNNs) have recently evinced immense success for various image recognition tasks. However, a question of paramount importance is somewhat unanswered in deep learning research - is the selected CNN optimal for the dataset in terms of accuracy and model size? In this paper, we intend to answer this question and introduce a novel strategy that alters the architecture of a given CNN for a specified dataset, to potentially enhance the original accuracy while possibly reducing the model size. We use two operations for architecture refinement, viz. stretching and symmetrical splitting. Our procedure starts with a pre-trained CNN for a given dataset, and optimally decides the stretch and split factors across the network to refine the architecture. We empirically demonstrate the necessity of the two operations. We evaluate our approach on two natural scenes attributes datasets, SUN Attributes and CAMIT-NSAD, with architectures of GoogleNet and VGG-11, that are quite contrasting in their construction. We justify our choice of datasets, and show that they are interestingly distinct from each other, and together pose a challenge to our architectural refinement algorithm. Our results substantiate the usefulness of the proposed method.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1604.06832},
  Eprint                   = {1604.06832},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shankar et al. - 2016 - Refining Architectures of Deep Convolutional Neural Networks.pdf:pdf},
  Url                      = {http://arxiv.org/abs/1604.06832}
}

@InProceedings{shankar2016refining,
  Title                    = {{Refining Architectures of Deep Convolutional Neural Networks}},
  Author                   = {Shankar, Sukrit and Robertson, Duncan and Ioannou, Yani and Criminisi, Antonio and Cipolla, Roberto},
  Booktitle                = {{Conference on Computer Vision and Pattern Recognition (CVPR), 2016}},
  Year                     = {2016}
}

@Misc{conf/cvpr/ShottonFCSFMKB11,
  Title                    = {{Real-time human pose recognition in parts from single depth images}},

  Author                   = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
  Year                     = {2011},

  Abstract                 = {We propose a new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes. The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.},
  Booktitle                = {{Computer Vision and Pattern Recognition (CVPR)}},
  Institution              = {Microsoft Research Cambridge {\&} Xbox Incubation},
  ISBN                     = {9781457703935},
  ISSN                     = {10636919},
  Number                   = {3},
  Pages                    = {1297--1304},
  Publisher                = {IEEE},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995316},
  Volume                   = {2}
}

@Article{Siegmann2008,
  Title                    = {{Fundaments in luminance and retroreflectivity measurements of vertical traffic signs using a color digital camera}},
  Author                   = {Siegmann, Philip},
  Journal                  = {and Measurement,},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {607--615},
  Volume                   = {57},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siegmann - 2008 - Fundaments in luminance and retroreflectivity measurements of vertical traffic signs using a color digital camera.pdf:pdf},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4407733}
}

@InProceedings{sietsma1988neural,
  Title                    = {{Neural net pruning-why and how}},
  Author                   = {Sietsma, Jocelyn and Dow, Robert JF},
  Booktitle                = {{IEEE International Conference on Neural Networks}},
  Year                     = {1988},
  Organization             = {IEEE San Diego},
  Pages                    = {325--333},
  Volume                   = {1}
}

@InProceedings{Simonyan2014verydeep,
  Title                    = {{Very deep convolutional networks for large-scale image recognition}},
  Author                   = {Simonyan, K and Zisserman, A},
  Booktitle                = {{eprint ar{\{}X{\}}iv:arXiv:1409.1556v5}},
  Year                     = {1409},

  Abstract                 = {Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) ...}
}

@InCollection{NIPS2016_6205,
  Title                    = {{Swapout: Learning an ensemble of deep architectures}},
  Author                   = {Singh, Saurabh and Hoiem, Derek and Forsyth, David},
  Booktitle                = {{Advances in Neural Information Processing Systems 29}},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2016},
  Editor                   = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  Pages                    = {28--36}
}

@Article{journals/pami/SironiTRLF15,
  Title                    = {{Learning separable filters}},
  Author                   = {Sironi, Amos and Tekin, Bugra and Rigamonti, Roberto and Lepetit, Vincent and Fua, Pascal},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2015},
  Number                   = {1},
  Pages                    = {94--106},
  Volume                   = {37},

  Abstract                 = {Learning filters to produce sparse image representations in terms of $\backslash$nover complete dictionaries has emerged as a powerful way to create image $\backslash$nfeatures for many different purposes. Unfortunately, these filters are usually $\backslash$nboth numerous and non-separable, making their use computationally expensive. In $\backslash$nthis paper, we show that such filters can be computed as linear combinations of $\backslash$na smaller number of separable ones, thus greatly reducing the computational $\backslash$ncomplexity at no cost in terms of performance. This makes filter learning $\backslash$napproaches practical even for large images or 3D volumes, and we show that we $\backslash$nsignificantly outperform state-of-the-art methods on the linear structure $\backslash$nextraction task, in terms of both accuracy and speed. Moreover, our approach is $\backslash$ngeneral and can be used on generic filter banks to reduce the complexity of the $\backslash$nconvolutions.},
  Doi                      = {10.1109/TPAMI.2014.2343229},
  ISBN                     = {978-0-7695-4989-7},
  ISSN                     = {01628828},
  Keywords                 = {Convolutional neural networks; Convolutional sparse coding; Features extraction; Filter learning; Image denoising; Segmentation of linear structures; Separable convolution; Tensor decomposition},
  Pmid                     = {26353211}
}

@InProceedings{Snoek2012,
  Title                    = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
  Author                   = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan Prescott},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2012},
  Pages                    = {2960--2968},

  Archiveprefix            = {arXiv},
  Arxivid                  = {1206.2944},
  Eprint                   = {1206.2944},
  ISBN                     = {9781627480031},
  ISSN                     = {10495258},
  Pmid                     = {9377276}
}

@Article{dropoutjmlr,
  Title                    = {{Dropout : A Simple Way to Prevent Neural Networks from Overfitting}},
  Author                   = {Srivastava, Nitish and Hinton, Geoffrey E. and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  Journal                  = {Journal of Machine Learning Research (JMLR)},
  Year                     = {2014},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {1929--1958},
  Volume                   = {15},

  Abstract                 = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different ``thinned'' networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1102.4807},
  Doi                      = {10.1214/12-AOS1000},
  Eprint                   = {1102.4807},
  ISBN                     = {1532-4435},
  ISSN                     = {15337928},
  Keywords                 = {deep learning; model combination; neural networks; regularization},
  Publisher                = {JMLR.org}
}

@InProceedings{Sutskever2013momentum,
  Title                    = {{On the importance of initialization and momentum in deep learning}},
  Author                   = {Sutskever, Ilya and Martens, James and Dahl, George E and Hinton, Geoffrey E},
  Booktitle                = {{Proceedings of the 30th International Conference on Machine Learning, {\{}ICML{\}} 2013, Atlanta, GA, USA, 16-21 June 2013}},
  Year                     = {2013},
  Pages                    = {1139--1147},
  Publisher                = {JMLR.org},
  Series                   = {{{\{}JMLR{\}} Workshop and Conference Proceedings}},
  Volume                   = {28},

  Url                      = {http://jmlr.org/proceedings/papers/v28/sutskever13.html}
}

@InProceedings{Szegedy2014going,
  Title                    = {{Going Deeper with Convolutions}},
  Author                   = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  Booktitle                = {{Computer Vision and Pattern Recognition (CVPR)}},
  Year                     = {2015},

  Url                      = {http://arxiv.org/abs/1409.4842}
}

@InProceedings{szegedy2015rethinking,
  Title                    = {{Rethinking the Inception Architecture for Computer Vision}},
  Author                   = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  Booktitle                = {{Proceedings of IEEE Conference on Computer Vision and Pattern Recognition,}},
  Year                     = {2016},

  Url                      = {http://arxiv.org/abs/1512.00567}
}

@InProceedings{Deselaers2011visual,
  Title                    = {{Visual and Semantic Similarity in {\{}I{\}}mage{\{}N{\}}et}},
  Author                   = {{T. Deselaers}, V Ferrari},
  Booktitle                = {{Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2011}
}

@Article{Terzopoulos1988,
  Title                    = {{Constraints on deformable models: Recovering 3D shape and nonrigid motion}},
  Author                   = {Terzopoulos, D and Witkin, A and Kass, M},
  Journal                  = {Artificial intelligence},
  Year                     = {1988},
  Number                   = {1988},
  Pages                    = {91--123},
  Volume                   = {36},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terzopoulos, Witkin, Kass - 1988 - Constraints on deformable models Recovering 3D shape and nonrigid motion.pdf:pdf},
  Url                      = {http://www.sciencedirect.com/science/article/pii/000437028890080X}
}

@Misc{TheMendeleySupportTeam2011d,
  Title                    = {{Getting Started with Mendeley}},

  Author                   = {{The Mendeley Support Team}},
  Year                     = {2011},

  Abstract                 = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
  Address                  = {London},
  Booktitle                = {{Mendeley Desktop}},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
  Keywords                 = {Mendeley; how-to; user manual},
  Pages                    = {1--16},
  Publisher                = {Mendeley Ltd.},
  Url                      = {http://www.mendeley.com}
}

@Misc{TheMendeleySupportTeam2011e,
  Title                    = {{Getting Started with Mendeley}},

  Author                   = {{The Mendeley Support Team}},
  Year                     = {2011},

  Abstract                 = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
  Address                  = {London},
  Booktitle                = {{Mendeley Desktop}},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
  Keywords                 = {Mendeley; how-to; user manual},
  Pages                    = {1--16},
  Publisher                = {Mendeley Ltd.},
  Url                      = {http://www.mendeley.com}
}

@InProceedings{Tompson_2015_CVPR,
  Title                    = {{Efficient Object Localization Using Convolutional Networks}},
  Author                   = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
  Booktitle                = {{The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
  Year                     = {2015},
  Month                    = {jun}
}

@Book{Trucco1998,
  Title                    = {{Introductory techniques for 3-D computer vision}},
  Author                   = {Trucco, Emanuele and Verri, Alessandro},
  Publisher                = {Prentice Hall},
  Year                     = {1998},

  ISBN                     = {0132611082}
}

@InProceedings{Tsin2001,
  Title                    = {{Statistical calibration of CCD imaging process}},
  Author                   = {Tsin, Y. and Ramesh, V. and Kanade, T.},
  Booktitle                = {{Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}},
  Year                     = {2001},
  Pages                    = {480--487},
  Publisher                = {IEEE Comput. Soc},
  Volume                   = {1},

  Doi                      = {10.1109/ICCV.2001.937555},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsin, Ramesh, Kanade - 2001 - Statistical calibration of CCD imaging process.pdf:pdf},
  ISBN                     = {0-7695-1143-0},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=937555}
}

@InProceedings{ullrich2017soft,
  Title                    = {{Soft Weight-Sharing for Neural Network Compression}},
  Author                   = {Ullrich, Karen and Meeds, Edward and Welling, Max},
  Booktitle                = {{International Conference on Learning Representations}},
  Year                     = {2017},

  Archiveprefix            = {arXiv},
  Arxivid                  = {1702.04008}
}

@PhdThesis{Unnikrishnan2008a,
  Title                    = {{Statistical Approaches to Multi-scale Point Cloud Processing}},
  Author                   = {Unnikrishnan, Ranjith},
  School                   = {Carnegie Mellon University},
  Year                     = {2008},

  Booktitle                = {{wwwoldricmuedu}},
  Number                   = {May},
  Pages                    = {1-----146},
  Publisher                = {CARNEGIE MELLON UNIVERSITY},
  Url                      = {http://www-old.ri.cmu.edu/pubs/pub{\_}6112{_}text.html}
}

@Article{Unnikrishnan2008,
  Title                    = {{Multi-scale interest regions from unorganized point clouds}},
  Author                   = {Unnikrishnan, Ranjith and Hebert, Martial},
  Journal                  = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
  Year                     = {2008},

  Month                    = {jun},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPRW.2008.4563030},
  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unnikrishnan, Hebert - 2008 - Multi-scale interest regions from unorganized point clouds(2).pdf:pdf},
  ISBN                     = {978-1-4244-2339-2},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4563030}
}

@Article{Unnikrishnan2008b,
  Title                    = {{Multi-scale interest regions from unorganized point clouds}},
  Author                   = {Unnikrishnan, Ranjith and Hebert, M},
  Journal                  = {Computer Vision and Pattern},
  Year                     = {2008},
  Number                   = {May},

  File                     = {:home/yani/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unnikrishnan, Hebert - 2008 - Multi-scale interest regions from unorganized point clouds.pdf:pdf},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4563030}
}

@InProceedings{vanhoucke2011improving,
  Title                    = {{Improving the speed of neural networks on CPUs}},
  Author                   = {Vanhoucke, Vincent and Senior, Andrew and Mao, Mz},
  Booktitle                = {{Proc. Deep Learning and {\ldots}}},
  Year                     = {2011},
  Pages                    = {1--8},
  Volume                   = {1},

  Abstract                 = {Recent advances in deep learning have made the use of large, deep neural net- works with tens of millions of parameters suitable for a number of applications that require real-time processing. The sheer size of these networks can represent a challenging computational burden, even for modern CPUs. For this reason, GPUs are routinely used instead to train and run such networks. This paper is a tutorial for students and researchers on some of the techniques that can be used to reduce this computational cost considerably on modern x86 CPUs. We emphasize data layout, batching of the computation, the use of SSE2 instructions, and particularly leverage SSSE3 and SSE4 fixed-point instructions which provide a 3× improve- ment over an optimized floating-point baseline. We use speech recognition as an example task, and show that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10× speedup over an unoptimized baseline and a 4× speedup over an aggressively optimized floating-point baseline at no cost in accuracy. The techniques described extend readily to neural network training and provide an effective alternative to the use of specialized hardware.},
  ISSN                     = {9781450329569},
  Url                      = {http://research.google.com/pubs/archive/37631.pdf}
}

@InCollection{vapnik2015uniform,
  Title                    = {{On the uniform convergence of relative frequencies of events to their probabilities}},
  Author                   = {Vapnik, Vladimir N and Chervonenkis, A Ya},
  Booktitle                = {{Measures of Complexity}},
  Publisher                = {Springer},
  Year                     = {2015},
  Pages                    = {11--30}
}

@InProceedings{wager2013dropout,
  Title                    = {{Dropout Training as Adaptive Regularization}},
  Author                   = {Wager, S. and Wang, S. I. and Liang, P.},
  Booktitle                = {{Advances in Neural Information Processing Systems (NIPS)}},
  Year                     = {2013}
}

@InProceedings{icml2013_wan13,
  Title                    = {{Regularization of Neural Networks using DropConnect}},
  Author                   = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and Cun, Yann L. and Fergus, Rob},
  Booktitle                = {{Proceedings of the 30th International Conference on Machine Learning (ICML-13)}},
  Year                     = {2013},
  Editor                   = {Dasgupta, Sanjoy and Mcallester, David},
  Month                    = may,
  Number                   = {3},
  Pages                    = {1058--1066},
  Publisher                = {JMLR Workshop and Conference Proceedings},
  Volume                   = {28},

  Abstract                 = {We introduce DropConnect, a generalization of DropOut, for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recoginition benchmarks can be obtained by aggregating multiple DropConnect-trained models.}
}

@InProceedings{Welbl2014casting,
  Title                    = {{Casting Random Forests as Artificial Neural Networks (and Profiting from It)}},
  Author                   = {Welbl, J},
  Booktitle                = {{GCPR}},
  Year                     = {2014}
}

@TechReport{widrow1960adaptive,
  Title                    = {{Adaptive switching circuits}},
  Author                   = {Widrow, Bernard and Hoff, Marcian E},
  Institution              = {Stanford University},
  Year                     = {1960}
}

@Article{wolpert1996lack,
  Title                    = {{The lack of a priori distinctions between learning algorithms}},
  Author                   = {Wolpert, David H},
  Journal                  = {Neural computation},
  Year                     = {1996},
  Number                   = {7},
  Pages                    = {1341--1390},
  Volume                   = {8},

  Publisher                = {MIT Press}
}

@InProceedings{Wu2015scalingup,
  Title                    = {{Deep Image: Scaling up Image Recognition}},
  Author                   = {Wu, Ren and Yan, Shengen and Shan, Yi and Dang, Qingqing and Sun, Gang},
  Booktitle                = {{Arxiv}},
  Year                     = {2015},
  Pages                    = {12},

  Abstract                 = {We present a state-of-the-art image recognition system, Deep Image, developed using end-to-end deep learning. The key components are a custom-built supercomputer dedicated to deep learning, a highly optimized parallel algorithm using new strategies for data partitioning and communication, larger deep neural network models, novel data augmentation approaches, and usage of multi-scale high-resolution images. On one of the most challenging computer vision benchmarks, the ImageNet classification challenge, our system has achieved the best result to date, with a top-5 error rate of 5.33{\%}, a relative 20.0{\%} improvement over the previous best result.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1501.02876},
  Doi                      = {10.1007/3-540-60220-8},
  Eprint                   = {1501.02876},
  ISBN                     = {9781931971164 1931971161},
  ISSN                     = {0031921X},
  Pmid                     = {903},
  Url                      = {http://arxiv.org/abs/1501.02876}
}

@InProceedings{2016arXiv161105431X,
  Title                    = {{Aggregated Residual Transformations for Deep Neural Networks}},
  Author                   = {{Xie}, S. and {Girshick}, R. and {Doll{\'a}r}, P. and {Tu}, Z. and {He}, K.},
  Booktitle                = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017, Honolulu, Hawaii}},
  Year                     = {2017},

  Archiveprefix            = {arXiv},
  Eprint                   = {1611.05431},
  Keywords                 = {Computer Science - Computer Vision and Pattern Recognition},
  Primaryclass             = {cs.CV}
}

@InProceedings{xu2014deep,
  Title                    = {{Deep convolutional neural network for image deconvolution}},
  Author                   = {Xu, Li and Ren, Jimmy S and Liu, Ce and Jia, Jiaya},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014},
  Pages                    = {1790--1798}
}

@Article{Yang2012,
  Title                    = {{An Online Learned CRF Model for Multi-Target Tracking}},
  Author                   = {Yang, Bo and Nevatia, Ram},
  Journal                  = {Learning},
  Year                     = {2012}
}

@InProceedings{yi2016lift,
  Title                    = {{LIFT: Learned Invariant Feature Transform}},
  Author                   = {Yi, Kwang Moo and Trulls, Eduard and Lepetit, Vincent and Fua, Pascal},
  Booktitle                = {{European Conference on Computer Vision (ECCV)}},
  Year                     = {2016},

  Address                  = {Amsterdarm}
}

@Book{yu2014book,
  Title                    = {{Automatic Speech Recognition: A Deep Learning Approach}},
  Author                   = {Yu, Dong and Deng, Li},
  Publisher                = {Springer},
  Year                     = {2015},

  Booktitle                = {{Book}},
  Doi                      = {10.1007/978-1-4471-5779-3},
  ISBN                     = {9781447157786},
  ISSN                     = {1860-4862}
}

@Misc{1311.2901v3,
  Title                    = {{Visualizing and understanding convolutional networks}},

  Author                   = {Zeiler, Matthew D. and Fergus, Rob},
  Month                    = {nov},
  Year                     = {2014},

  Abstract                 = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  Annote                   = {published = 2013-11-12T20:02:22Z, updated = 2013-11-28T23:04:01Z},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1311.2901},
  Booktitle                = {{Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}},
  Doi                      = {10.1007/978-3-319-10590-1_53},
  Eprint                   = {1311.2901},
  ISBN                     = {9783319105895},
  ISSN                     = {16113349},
  Number                   = {PART 1},
  Pages                    = {818--833},
  Pmid                     = {26353135},
  Volume                   = {8689 LNCS}
}

@InProceedings{Zeiler2010Deconv,
  Title                    = {{Deconvolutional Networks}},
  Author                   = {Zeiler, M D and Krishnan, D and Taylor, G W and R.Fergus},
  Booktitle                = {{Proceedings of the 2010 IEEE Conference on Computer Vision and Pattern Recognition}},
  Year                     = {2010}
}

@InProceedings{rethinking2016,
  Title                    = {{Understanding deep learning requires rethinking generalization}},
  Author                   = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  Year                     = {2017},

  Archiveprefix            = {arXiv},
  Arxivid                  = {1611.03530},
  Eprint                   = {1611.03530},
  Journal                  = {International Conference on Learning Representations (ICLR)},
  Location                 = {Toulon, France}
}

@Article{Zhang1999,
  Title                    = {{Shape from Shading : A Survey}},
  Author                   = {Zhang, Ruo and Tsai, Ping-sing and Cryer, James Edwin and Shah, Mubarak},
  Journal                  = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  Year                     = {1999},
  Number                   = {8},
  Pages                    = {1--41},
  Volume                   = {21},

  Abstract                 = {Since the first shape-from-shading (SFS) technique was developed by Horn in the early 1970s, many different approaches have emerged. In this paper, six well-known SFS algorithms are implemented and compared. The performance of the algorithms was analyzed on synthetic images using mean and standard deviation of depth (Z) error, mean of surface gradient (p, q) error, and CPU timing. Each algorithm works well for certain images, but performs poorly for others. In general, minimization approaches are more robust, while the other approaches are faster},
  Doi                      = {10.1109/34.784284},
  Institution              = {University of Central Florida},
  ISSN                     = {01628828},
  Keywords                 = {analysis algorithms; cda 9222798; lambertian model; nsf grants cda 9122006; shape from shading; survey; work supported},
  Publisher                = {IEEE},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=784284}
}

@Article{zhang2017primal,
  Title                    = {{Primal-Dual Group Convolutions for Deep Neural Networks}},
  Author                   = {Zhang, Ting and Qi, Guo-Jun and Xiao, Bin and Wang, Jingdong},
  Journal                  = {arXiv preprint arXiv:1707.02725},
  Year                     = {2017},

  Owner                    = {yani},
  Timestamp                = {2017.09.13}
}

@Misc{1505.06798v1,
  Title                    = {{Accelerating Very Deep Convolutional Networks for Classification and Detection}},

  Author                   = {Zhang, Xiangyu and Zou, Jianhua and He, Kaiming and Sun, Jian},
  Month                    = {may},
  Year                     = {2015},

  Abstract                 = {This paper aims to accelerate the test-time computation of convolutional neural networks (CNNs), especially very deep CNNs that have substantially impacted the computer vision community. Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We develop an effective solution to the resulting nonlinear optimization problem without the need of stochastic gradient descent (SGD). More importantly, while current methods mainly focus on optimizing one or two layers, our nonlinear method enables an asymmetric reconstruction that reduces the rapidly accumulated error when multiple (e.g., {\textgreater}=10) layers are approximated. For the widely used very deep VGG-16 model, our method achieves a whole-model speedup of 4x with merely a 0.3{\%} increase of top-5 error in ImageNet classification. Our 4x accelerated VGG-16 model also shows a graceful accuracy degradation for object detection when plugged into the latest Fast R-CNN detector.},
  Annote                   = {published = 2015-05-26T03:30:59Z, updated = 2015-05-26T03:30:59Z, Technical report. arXiv admin note: substantial text overlap with arXiv:1411.4229},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1505.06798},
  Booktitle                = {{Pattern Analysis and Machine Intelligence, IEEE Transactions on}},
  Doi                      = {10.1109/TPAMI.2015.2502579},
  Eprint                   = {1505.06798},
  ISSN                     = {0162-8828},
  Pages                    = {1--14},
  Pmid                     = {26599615},
  Url                      = {http://arxiv.org/abs/1505.06798}
}

@Misc{1411.4229v1,
  Title                    = {{Efficient and Accurate Approximations of Nonlinear Convolutional Networks}},

  Author                   = {Zhang, Xiangyu and Zou, Jianhua and Ming, Xiang and He, Kaiming and Sun, Jian},
  Month                    = {nov},
  Year                     = {2014},

  Abstract                 = {This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs). Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We minimize the reconstruction error of the nonlinear responses, subject to a low-rank constraint which helps to reduce the complexity of filters. We develop an effective solution to this constrained nonlinear optimization problem. An algorithm is also presented for reducing the accumulated error when multiple layers are approximated. A whole-model speedup ratio of 4x is demonstrated on a large network trained for ImageNet, while the top-5 error rate is only increased by 0.9{\%}. Our accelerated model has a comparably fast speed as the "AlexNet", but is 4.7{\%} more accurate.},
  Annote                   = {published = 2014-11-16T08:37:25Z, updated = 2014-11-16T08:37:25Z},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1411.4229},
  Eprint                   = {1411.4229},
  ISBN                     = {9781467369640},
  Url                      = {http://arxiv.org/abs/1411.4229}
}

@InProceedings{Zhang2015efficient,
  Title                    = {{Efficient and Accurate Approximations of Nonlinear Convolutional Networks}},
  Author                   = {Zhang, Xiangyu and Zou, Jianhua and Ming, Xiang and He, Kaiming and Sun, Jian},
  Booktitle                = {{eprint ar{\{}X{\}}iv:1411.4229v1}},
  Year                     = {2014},

  Abstract                 = {This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs). Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We minimize the reconstruction error of the nonlinear responses, subject to a low-rank constraint which helps to reduce the complexity of filters. We develop an effective solution to this constrained nonlinear optimization problem. An algorithm is also presented for reducing the accumulated error when multiple layers are approximated. A whole-model speedup ratio of 4x is demonstrated on a large network trained for ImageNet, while the top-5 error rate is only increased by 0.9{\%}. Our accelerated model has a comparably fast speed as the "AlexNet", but is 4.7{\%} more accurate.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1411.4229},
  Eprint                   = {1411.4229},
  ISBN                     = {9781467369640},
  Url                      = {http://arxiv.org/abs/1411.4229}
}

@InProceedings{zhou2014learning,
  Title                    = {{Learning Deep Features for Scene Recognition using Places Database}},
  Author                   = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
  Booktitle                = {{Advances in Neural Information Processing Systems 27}},
  Year                     = {2014},
  Pages                    = {487--495},

  Abstract                 = {Scene recognition is one of the hallmark tasks of computer vision, allowing definition of a context for object recognition. Whereas the tremendous recent progress in object recognition tasks is due to the availability of large datasets like ImageNet and the rise of Convolutional Neural Networks (CNNs) for learning high-level features, performance at scene recognition has not attained the same level of success. This may be because current deep features trained from ImageNet are not competitive enough for such tasks. Here, we introduce a new scene-centric database called Places with over 7 million labeled pictures of scenes. We propose new methods to compare the density and diversity of image datasets and show that Places is as dense as other scene datasets and has more diversity. Using CNN, we learn deep features for scene recognition tasks, and establish new state-of-the-art results on several scene-centric datasets. A visualization of the CNN layers' responses allows us to show differences in the internal representations of object-centric and scene-centric networks.},
  ISSN                     = {10495258},
  Url                      = {http://papers.nips.cc/paper/5349-learning-deep-features-for-scene-recognition-using-places-database.pdf}
}

@Article{Zickler,
  Title                    = {{Color subspaces as photometric invariants}},
  Author                   = {Zickler, T. and Mallick, S.P.},
  Journal                  = {International Journal of {\ldots}},
  Year                     = {2008},
  Pages                    = {2000--2010},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2006.77},
  File                     = {:home/yani/Downloads/ColorSubspaces{\_}IJCV.pdf:pdf},
  ISBN                     = {0-7695-2597-0},
  Publisher                = {Ieee},
  Url                      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640998 http://www.springerlink.com/index/383064l520t33622.pdf}
}

@InProceedings{segmentation-of-brain-tumor-tissues-with-convolutional-neural-networks,
  Title                    = {{Segmentation of Brain Tumor Tissues with Convolutional Neural Networks}},
  Author                   = {Zikic, Darko and Ioannou, Yani and Brown, Matthew and Criminisi, Antonio},
  Booktitle                = {{MICCAI workshop on Multimodal Brain Tumor Segmentation Challenge (BRATS)}},
  Year                     = {2014},
  Month                    = {oct},
  Publisher                = {Springer}
}

@Proceedings{Bach2015,
  Title                    = {{Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015}},
  Year                     = {2015},
  Editor                   = {Bach, Francis R and Blei, David M},
  Volume                   = {37},

  Booktitle                = {{ICML}}
}

@Proceedings{conf/icml/2015,
  Title                    = {{Proceedings of the 32nd International Conference on Machine Learning, {\{}ICML{\}} 2015, Lille, France, 6-11 July 2015}},
  Year                     = {2015},
  Editor                   = {Bach, Francis R and Blei, David M},
  Publisher                = {JMLR.org},
  Series                   = {{{\{}JMLR{\}} Workshop and Conference Proceedings}},
  Volume                   = {37},

  Url                      = {http://jmlr.org/proceedings/papers/v37/}
}

@Proceedings{conf/icml/2010,
  Title                    = {{Proceedings of the 27th International Conference on Machine Learning (ICML-10), June 21-24, 2010, Haifa, Israel}},
  Year                     = {2010},
  Editor                   = {F{\"u}rnkranz, Johannes and Joachims, Thorsten},
  Publisher                = {Omnipress},

  Booktitle                = {{ICML}},
  Keywords                 = {dblp},
  Url                      = {http://dblp.uni-trier.de/db/conf/icml/icml2010.html}
}

@Proceedings{conf/iccv/2015,
  Title                    = {{2015 {\{}IEEE{\}} International Conference on Computer Vision, {\{}ICCV{\}} 2015, Santiago, Chile, December 7-13, 2015}},
  Year                     = {2015},
  Publisher                = {{\{}IEEE{\}} Computer Society},

  ISBN                     = {978-1-4673-8391-2},
  Url                      = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7407725}
}

@Proceedings{conf/cvpr/2013,
  Title                    = {{2013 {\{}IEEE{\}} Conference on Computer Vision and Pattern Recognition, Portland, OR, USA, June 23-28, 2013}},
  Year                     = {2013},
  Publisher                = {IEEE}
}

@Proceedings{conf/icml/2013,
  Title                    = {{Proceedings of the 30th International Conference on Machine Learning, {\{}ICML{\}} 2013, Atlanta, GA, USA, 16-21 June 2013}},
  Year                     = {2013},
  Publisher                = {JMLR.org},
  Series                   = {{{\{}JMLR{\}} Workshop and Conference Proceedings}},
  Volume                   = {28},

  Url                      = {http://jmlr.org/proceedings/papers/v28/}
}

