\documentclass[thesis]{subfiles}

\begin{document}

\chapter{Methodology}
\label{methodology}
% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Figs/Raster/}{Figs/PDF/}{Figs/}}
\else
    \graphicspath{{Figs/Vector/}{Figs/}}
\fi

\section{Generalising Neural Networks and Decision Trees}
Although the relationship between neural networks and decision trees has been explored in the past, in the case of Entropy Nets~\cite{Sethi1990} this was with the intention of training and creating neural networks with decision-tree approaches, while in the case of TODO~\cite{Welbl2014casting}.

Here we explore the relationship, with the objective of reducing the connectivity of deep neural networks trained with back-propagation, specifically convolutional neural networks. 

Towards this objective, we generalize neural networks and decision trees intuitively by using a new graphical notation for representing both. This notation isolates the differences between the two models, such that we can represent a hybrid model, i.e. Conditional Network, compactly.\footnote{This notation was created by Dr. Antonio Criminisi, and is not a contribution of this thesis.}
\end{document}